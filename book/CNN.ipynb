{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN example pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,super).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,5)#input,output,m(mxm dimensions) kernel\n",
    "        self.pool=nn.MaxPool2d(2,2)#reduce the size of the feature map to 2X2\n",
    "        self.conv2=nn.Conv2d(6,16,5)#16 output channels\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)#10 output classes hence 10 neurons\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)#reshapes the data -1 lets the batch size be chosen by pytorch and 16*5*5 is the reshaped size\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x),dim=1)#softmax converts the raw values to probabilities hence returning the probabilities for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training using the CIFAR-10 dataset (defining the data loaders)\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),#images to range [0,1]\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))#normalize to range [-1,1]\n",
    "])\n",
    "\n",
    "trainset=torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)# to dowload training dataset\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=4,shuffle=True,num_workers=2)#load the data in batches\n",
    "testset=torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)#for test data\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=4,shuffle=True,num_workers=2)#dataloader for test data\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a CNN model using tensorflow\n",
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(32,32,3)))#32x32 pixels with 3 color channels\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))#kernel is 3x3 and there are 32 kernels\n",
    "model.add(MaxPooling2D((2,2)))#2x2 dimensions for applying pooling \n",
    "model.add(Conv2D(64,(3,3),activation='relu'))#64 kernels kernels are 3x3\n",
    "model.add(MaxPooling2D((2,2)))#2x2 dimensions for applying pooling \n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())#flatten the output of the conv layers\n",
    "model.add(Dense(64,activation='relu'))#added a fully connected layer\n",
    "model.add(Dense(10))#output layer\n",
    "\n",
    "#here we have 3 conv layers 1st has 32 kernels rest 2 have 64 kernels when we flatten the output then we created a fully connected layer and output layer\n",
    "#for classification tasks we generally add 1 or 2 fully connected layer\n",
    "#in a conv layer the ouytput is 3d hence we need to flatten it as the fully connected layer expects 1d input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in pytorch \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,32,3)#input channels,output channels,kernels size(3x3)\n",
    "        self.pool=nn.MaxPool2d(2,2)#converts feature map to 2x2 matrix\n",
    "        self.conv2=nn.Conv2d(32,64,3)#same as above\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.fc1=nn.Linear(64*5*5,120)#input size , output channels also the size here should be 64*6*6 look into it\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))#applied activation relu function on the conv layer\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        print(x.shape())\n",
    "        x=x.view(-1,64*5*5)#flatten the tensor from 64 channel of 5x5 feature map to 64*5*5    \n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x),dim=1)#applies softmax accross each row\n",
    "\n",
    "net1=net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
