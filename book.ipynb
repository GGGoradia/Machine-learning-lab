{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n"
     ]
    }
   ],
   "source": [
    "array=np.array([[1,'a'],[2,'b']])\n",
    "df=pd.DataFrame(array,columns=['A','B'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0,'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A  B\n",
      "0  1.0  a\n",
      "1  2.0  b\n",
      "2  0.0  c\n",
      "     A  B\n",
      "0  1.0  a\n",
      "1  2.0  b\n",
      "2  0.0  c\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan],\n",
    "    'B': ['a', 'b', 'c'],\n",
    "})\n",
    "\n",
    "# Fill missing values\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)\n",
    "\n",
    "# Replace values\n",
    "df_replaced = df.replace(np.nan, 0)\n",
    "print(df_replaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "2.0\n",
      "6\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "})\n",
    "print(df)\n",
    "# Calculate the mean of a column\n",
    "print(df['A'].mean())\n",
    "\n",
    "# Calculate the sum of a column\n",
    "print(df['A'].sum())\n",
    "\n",
    "# Calculate the maximum value of a column\n",
    "print(df['A'].max())\n",
    "\n",
    "# Calculate the minimum value of a column\n",
    "print(df['A'].min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.0\n",
      "mean     2.0\n",
      "std      1.0\n",
      "min      1.0\n",
      "25%      1.5\n",
      "50%      2.0\n",
      "75%      2.5\n",
      "max      3.0\n",
      "Name: A, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['A'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A      B         C         D\n",
      "0  foo    one  1.428217 -0.839952\n",
      "1  bar    one  0.548146 -0.903671\n",
      "2  foo    two  0.460008 -1.030344\n",
      "3  bar  three -0.421819  0.302343\n",
      "4  foo    two -0.457489  0.857025\n",
      "5  bar    two -2.964766  0.660929\n",
      "6  foo    one  1.637333 -1.826346\n",
      "7  foo  three  2.442661 -0.363491\n",
      "                     B         C         D\n",
      "A                                         \n",
      "bar        onethreetwo -2.838439  0.059602\n",
      "foo  onetwotwoonethree  5.510731 -3.203109\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],\n",
    "    'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "    'C': np.random.randn(8),\n",
    "    'D': np.random.randn(8)\n",
    "})\n",
    "print(df)\n",
    "\n",
    "# Group by column 'A' and calculate the sum of 'C' and 'D' for each group\n",
    "grouped = df.groupby('A').sum()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B key   C   D\n",
      "0  A0  B0  K0  C0  D0\n",
      "1  A1  B1  K1  C1  D1\n",
      "2  A2  B2  K0  C0  D0\n",
      "3  A3  B3  K1  C1  D1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "    'key': ['K0', 'K1', 'K0', 'K1']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'C': ['C0', 'C1'],\n",
    "    'D': ['D0', 'D1']},\n",
    "    index=['K0', 'K1']\n",
    ")\n",
    "\n",
    "# Merge df1 and df2 on the 'key' column\n",
    "merged = pd.merge(df1, df2, left_on='key', right_index=True)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 Re-exported for typing.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     cm \u001b[38;5;28;01mas\u001b[39;00m cm, get_backend \u001b[38;5;28;01mas\u001b[39;00m get_backend, rcParams \u001b[38;5;28;01mas\u001b[39;00m rcParams, style \u001b[38;5;28;01mas\u001b[39;00m style)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pylab_helpers\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interactive  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\style\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m available, context, library, reload_library, use\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreload_library\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\style\\core.py:233\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m main_dict\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Load style library\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# ==================\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m _base_library \u001b[38;5;241m=\u001b[39m \u001b[43mread_style_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_LIBRARY_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m library \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    235\u001b[0m available \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\style\\core.py:211\u001b[0m, in \u001b[0;36mread_style_directory\u001b[1;34m(style_dir)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m Path(style_dir)\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTYLE_EXTENSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warns:\n\u001b[1;32m--> 211\u001b[0m         styles[path\u001b[38;5;241m.\u001b[39mstem] \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m warns:\n\u001b[0;32m    213\u001b[0m         _log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, path, w\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:870\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    869\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 870\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:847\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[1;32m--> 847\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[1;32m<frozen codecs>:309\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [1, 4, 9, 16, 25]\n",
    "\n",
    "# Create a line plot\n",
    "plt.plot(x, y)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Square Numbers')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Square')\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [1, 4, 9, 16, 25]\n",
    "})\n",
    "\n",
    "# Create a scatter plot with a regression line\n",
    "sns.regplot(x='x', y='y', data=df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHVCAYAAAB8NLYkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMu0lEQVR4nO3deXxU9b3/8fdkm4QsExKyQpYBBBQI1AAhgCKCRIQgFVuX2gbF6q8XUMSfXvH2FlF/xap1uyL1tizaSl3aooICIgoURJBg2BRkSVjMwprJRiYhOb8/AgNDAiSQZJKT1/PxmIeZ7/nOzGeOh/DmnPP9fi2GYRgCAABAq+fl6QIAAADQOAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2ANAKTJgwQUFBQZ4uA0ALR7AD4Gbbtm26/fbblZCQIH9/f3Xs2FE33XST/ud//sfTpTW5G264QRaLRenp6bW25eTkyGKx6MUXX/RAZQBQPwQ7AC5fffWV+vXrpy1btujXv/61Xn/9dd1///3y8vLSq6++6unyms2SJUuUmZnp6TIAoMF8PF0AgJbj//2//yebzaZvvvlGoaGhbtsOHz7smaLqwTAMlZeXKyAg4IrfKz4+XsXFxZo5c6Y+/vjjRqiu9WjM/QjAMzhjB8Bl79696tmzZ61QJ0mRkZFuz51Opx555BFFREQoODhYY8eO1aFDh2SxWPTUU0+5+k2YMEGJiYm13u+pp56SxWJxa5s/f75uvPFGRUZGymq16pprrtGcOXNqvTYxMVFjxozR8uXL1a9fPwUEBOjNN9+UJBUWFmrq1KmKi4uT1WpV165d9Yc//EHV1dX12gfBwcF65JFHtHjxYm3evPmifev6DpK0YMECWSwW5eTk1Kp51apVrpp79+6tVatWSZL+9a9/qXfv3vL391dycrK+/fbbOj9z3759SktLU2BgoGJjY/X000/LMAy3PtXV1XrllVfUs2dP+fv7KyoqSg8++KBOnDjh1u9i+3HFihUaMmSIQkNDFRQUpO7du+vJJ5+81O4D4GEEOwAuCQkJyszM1Pbt2y/Z9/7779crr7yikSNH6rnnnpOvr69Gjx59RZ8/Z84cJSQk6Mknn9Qf//hHxcXF6T/+4z80e/bsWn137dqlu+66SzfddJNeffVV9e3bV2VlZRo6dKj+9re/6Ve/+pVee+01DR48WNOnT9e0adPqXcfDDz+s9u3buwXUxrBnzx7dfffdSk9P16xZs3TixAmlp6frnXfe0SOPPKJ77rlHM2fO1N69e/Xzn/+8VhitqqrSzTffrKioKD3//PNKTk7WjBkzNGPGDLd+Dz74oB577DENHjxYr776qu6991698847SktLU2VlpVvfuvbjjh07NGbMGDmdTj399NP64x//qLFjx2rdunWNuj8ANAEDAE777LPPDG9vb8Pb29tITU01Hn/8cWP58uVGRUWFW7+srCxDkvEf//Efbu133323IcmYMWOGqy0jI8NISEio9VkzZswwzv8VVFZWVqtfWlqa0blzZ7e2hIQEQ5KxbNkyt/ZnnnnGCAwMNH744Qe39ieeeMLw9vY2Dhw4cMHvbhiGMXToUKNnz56GYRjGzJkzDUlGZmamYRiGkZ2dbUgyXnjhhYt+B8MwjPnz5xuSjOzs7Fo1f/XVV6625cuXG5KMgIAAY//+/a72N99805BkfPnll662jIwMQ5IxZcoUV1t1dbUxevRow8/Pzzhy5IhhGIbx73//25BkvPPOO241LVu2rFb7hfbjyy+/bEhyvSeA1oMzdgBcbrrpJq1fv15jx47Vli1b9PzzzystLU0dO3Z0u9/s008/lSQ99NBDbq+fOnXqFX3+ufd2ORwOHT16VEOHDtW+ffvkcDjc+trtdqWlpbm1ffDBB7ruuuvUvn17HT161PUYMWKEqqqqtGbNmnrXcuas3cyZM6/oO53rmmuuUWpqqut5SkqKJOnGG29UfHx8rfZ9+/bVeo/Jkye7frZYLJo8ebIqKir0+eefS6rZBzabTTfddJPbPkhOTlZQUJC+/PJLt/eraz+euRT/0Ucf1fsSNoCWgWAHwE3//v31r3/9SydOnNDGjRs1ffp0FRcX6/bbb9d3330nSdq/f7+8vLzUpUsXt9d27979ij573bp1GjFihAIDAxUaGqqIiAjXfV11Bbvz7d69W8uWLVNERITbY8SIEZIaNgDEZrNp6tSp+vjjjy94v1tDnRveznyGJMXFxdXZfv49cV5eXurcubNbW7du3STJdT/f7t275XA4FBkZWWs/lJSU1NoHde3HO+64Q4MHD9b999+vqKgo3XnnnXr//fcJeUArwKhYAHXy8/NT//791b9/f3Xr1k333nuvPvjgg1r3c11KXYMLpJr7xc61d+9eDR8+XD169NBLL72kuLg4+fn56dNPP9XLL79cK1TUNXKzurpaN910kx5//PE6P/NMCKqvhx9+WC+//LJmzpypV155pdb2+n63M7y9vRvUbpw3KKI+qqurFRkZqXfeeafO7REREW7P69qPAQEBWrNmjb788kt98sknWrZsmd577z3deOON+uyzzy5YLwDPI9gBuKR+/fpJkvLy8iTVDLKorq7W3r173c7S7dq1q9Zr27dvr8LCwlrt+/fvd3u+ePFiOZ1Offzxx25nts6/dHgxXbp0UUlJiesM3ZU6c9buqaeeUkZGRq3t7du3l1QzEvfckcTnf7fGUl1drX379rkF1B9++EGSXCOPu3Tpos8//1yDBw++omlLvLy8NHz4cA0fPlwvvfSSfv/73+u//uu/9OWXXzba/gXQ+LgUC8Dlyy+/rPMs0Zl76s6EuFGjRkmSXnvtNbd+dZ3V6tKlixwOh7Zu3epqy8vL06JFi9z6nTkLdO7nOxwOzZ8/v971//znP9f69eu1fPnyWtsKCwt16tSper/XGVOnTlVoaKiefvrpWtvOXIo+99690tJSvfXWWw3+nPp6/fXXXT8bhqHXX39dvr6+Gj58uKSafVBVVaVnnnmm1mtPnTpVZ8g+3/Hjx2u19e3bV1LNNDcAWi7O2AFwmTJlisrKyvTTn/5UPXr0UEVFhb766iu99957SkxM1L333iup5i/5u+66S2+88YYcDocGDRqklStXas+ePbXe884779R//ud/6qc//akeeughlZWVac6cOerWrZvbPHEjR46Un5+f0tPT9eCDD6qkpER//vOfFRkZ6TpTeCmPPfaYPv74Y40ZM0YTJkxQcnKySktLtW3bNv3jH/9QTk6OOnTo0KB9YrPZ9PDDD9c5iGLkyJGKj4/XxIkT9dhjj8nb21vz5s1TRESEDhw40KDPqQ9/f38tW7ZMGRkZSklJ0dKlS/XJJ5/oySefdF1iHTp0qB588EHNmjVLWVlZGjlypHx9fbV792598MEHevXVV3X77bdf9HOefvpprVmzRqNHj1ZCQoIOHz6sN954Q506ddKQIUMa/XsBaESeHZQLoCVZunSpcd999xk9evQwgoKCDD8/P6Nr167GlClTjIKCAre+J0+eNB566CEjPDzcCAwMNNLT042DBw/Wmu7EMGqmUenVq5fh5+dndO/e3fjb3/5W51QhH3/8sZGUlGT4+/sbiYmJxh/+8Adj3rx5dU4dMnr06Dq/Q3FxsTF9+nSja9euhp+fn9GhQwdj0KBBxosvvlhr2pbznTvdyblOnDhh2Gy2WtOdGIZhZGZmGikpKYafn58RHx9vvPTSSxec7qSumiUZkyZNcmura2qVjIwMIzAw0Ni7d68xcuRIo127dkZUVJQxY8YMo6qqqtb7/u///q+RnJxsBAQEGMHBwUbv3r2Nxx9/3MjNzb1kTStXrjRuvfVWIzY21vDz8zNiY2ONu+66q9Y0MgBaHothXMbduQBwARaLRTNmzGj0yX0BAJfGPXYAAAAmQbADAAAwCYIdAACASTAqFkCj4rZdAPAcztgBAACYRIs7Y1ddXa3c3FwFBwdfcLkeAACAtsIwDBUXFys2NlZeXhc/J9figl1ubm6tBbEBAADauoMHD6pTp04X7dPigl1wcLCkmuJDQkI8XA0AAIBnFRUVKS4uzpWRLqbFBbszl19DQkIIdgAAAKfV5xY1Bk8AAACYBMEOAADAJBoU7GbNmqX+/fsrODhYkZGRGjdunHbt2uXW54YbbpDFYnF7/J//838atWgAAADU1qBgt3r1ak2aNElff/21VqxYocrKSo0cOVKlpaVu/X79618rLy/P9Xj++ecbtWgAAABPKyqvlPNUlafLcNOgwRPLli1ze75gwQJFRkYqMzNT119/vau9Xbt2io6Ortd7Op1OOZ1O1/OioqKGlAQAANCs9h8r1fx1Ofpg00E9Nbanftav5UzTdkX32DkcDklSWFiYW/s777yjDh06qFevXpo+fbrKysou+B6zZs2SzWZzPZjDDgAAtDSGYWjDvmN64O1NuuHFVVrwVY5KK6q0atcRT5fmxmJc5sKO1dXVGjt2rAoLC7V27VpX+//+7/8qISFBsbGx2rp1q/7zP/9TAwYM0L/+9a8636euM3ZxcXFyOBxMdwIAADyq4lS1PtmWq7lrs7X9x7NXFYd2i9DEIXZdd1WHJl8pq6ioSDabrV7Z6LLnsZs0aZK2b9/uFuok6YEHHnD93Lt3b8XExGj48OHau3evunTpUut9rFarrFbr5ZYBAADQ6E6UVmjhxgN666scHS6uOQFl9fHSbdd20sQhieoaeenJgj3hsoLd5MmTtWTJEq1Zs+aSS1ukpKRIkvbs2VNnsAMAAGgp9hwu0bx12frX5kMqr6yWJEUGW/Wr1ATdnZKgsEA/D1d4cQ0KdoZhaMqUKVq0aJFWrVolu91+yddkZWVJkmJiYi6rQAAAgKZkGIbW7jmquWuz3e6Z6xkboolD7BqTFCs/n9Yx9W+Dgt2kSZO0cOFCffTRRwoODlZ+fr4kyWazKSAgQHv37tXChQt1yy23KDw8XFu3btUjjzyi66+/XklJSU3yBQAAAC5HeWWVPsr6UfPW5mhXQbEkyWKRRlwdpYlD7EqxhzX5/XONrUGDJy705ebPn68JEybo4MGDuueee7R9+3aVlpYqLi5OP/3pT/Xb3/623gMhGnKDIAAAQEMdKXbqr1/v1ztf79ex0gpJUjs/b/28X5wmDEpUYodAD1forskGT1wqA8bFxWn16tUNeUsAAIBm8V1ukeaty9bHWbmqqKq5f65jaIAyBiXojv7xsgX4erjCK3fZo2IBAABauupqQ1/uOqy5a7P11d5jrvafxIdq4hC7bu4ZLR/v1nH/XH0Q7AAAgOmUVZzSPzMPaf66HO07WrP0qbeXRTf3itbEIXZdG9/ewxU2DYIdAAAwjdzCk3prfY7+vuGAispPSZKC/X1014B4ZQxKVMfQAA9X2LQIdgAAoNXLOliouWuz9em2PFVV14wJSAhvp3sHJepn/eIUaG0bkadtfEsAAGA6p6qq9dl3BZq7NluZ+0+42lPsYZo4xK7hV0fJ26t1TVdypQh2AACgVSkqr9T73xzU/HU5+rHwpCTJ19ui9KRY3TfErl4dbR6u0HMIdgAAoFU4cKxM87/K1gebDqnEWXP/XPt2vvpFSoJ+lZqgyBB/D1foeQQ7AADQYhmGoW9yTmju2n1a8V2BTt8+p66RQbpvsF23XdtR/r7eni2yBSHYAQCAFqfiVLU+3ZanuWuzte1Hh6v9+m4Rum9wooZ2i2h1y301B4IdAABoMQrLKvTOhgN6e32OCoqckiSrj5duu7aj7h1sV7eoYA9X2LIR7AAAgMftPVKieWuz9c/Nh1ReWbPcV0SwVb8amKC7U+IVHmT1cIWtA8EOAAB4hGEYWrfnmOau3acvdx1xtV8TE6KJQ+wa0ydGVh/un2sIgh0AAGhW5ZVV+jgrV/PWZWtnfrEkyWKRhveI0sQhdg3sHMb9c5eJYAcAAJrFkWKn/vb1fr2zYb+OllRIktr5eetnyZ00YbBd9g6BHq6w9SPYAQCAJrUzv0hz/52tj7JyVVFVc/9crM1fGYMSdWf/eNna+Xq4QvMg2AEAgEZXXW1o1Q+HNXdtttbtOeZq7xsXqolD7Lq5V7R8vb08WKE5EewAAECjKas4pX9u/lHz12Vr35FSSZKXRRrVK0b3DbErOaG9hys0N4IdAAC4YvmOcr21PkcLNxyQ42SlJCnY6qM7B8QpY1CiOrVv5+EK2waCHQAAuGxbDxVq7tpsfbI1T6dOr/cVH9ZO9w5O1M/6xSnIStRoTuxtAADQIFXVhlZ8l6+5a7P1Tc4JV/sAe5gmDrFrxNVR8vZiuhJPINgBAIB6KS6v1PubDmnBV9k6ePykJMnHy6L0PrGaOMSuXh1tHq4QDRqOMmvWLPXv31/BwcGKjIzUuHHjtGvXLrc+5eXlmjRpksLDwxUUFKTx48eroKCgUYsGAADN5+DxMj2z5DulzvpCzyz5TgePn1RoO19NGtZF6564US/f0ZdQ10I06Izd6tWrNWnSJPXv31+nTp3Sk08+qZEjR+q7775TYGDNpIKPPPKIPvnkE33wwQey2WyaPHmybrvtNq1bt65JvgAAAGh8hmEoc/8JzV2breU78nX69jl1iQjUfUPsuu0nnRTgx3JfLY3FMAzjcl985MgRRUZGavXq1br++uvlcDgUERGhhQsX6vbbb5ck7dy5U1dffbXWr1+vgQMHXvI9i4qKZLPZ5HA4FBIScrmlAQCAy1BZVa1Pt+Vp3tpsbTnkcLVfd1UH3TfErqFXRciL++eaVUOy0RXdY+dw1PwPDwsLkyRlZmaqsrJSI0aMcPXp0aOH4uPjLxjsnE6nnE6nW/EAAKB5OcoqtXDjAb29Pkd5jnJJkp+Pl37at6PuG2JX9+hgD1eI+rjsYFddXa2pU6dq8ODB6tWrlyQpPz9ffn5+Cg0NdesbFRWl/Pz8Ot9n1qxZmjlz5uWWAQAArsC+IyWavy5H/8g8pJOVVZKkDkFW/XJggn4xMF4dgqwerhANcdnBbtKkSdq+fbvWrl17RQVMnz5d06ZNcz0vKipSXFzcFb0nAAC4MMMwtH7vMc1dm62VOw+72ntEB2viELvG9o2V1Yf751qjywp2kydP1pIlS7RmzRp16tTJ1R4dHa2KigoVFha6nbUrKChQdHR0ne9ltVpltfKvAQAAmprzVJU+zsrV3LXZ2plf7Gof3iNSE4fYldolXBYL98+1Zg0KdoZhaMqUKVq0aJFWrVolu93utj05OVm+vr5auXKlxo8fL0natWuXDhw4oNTU1MarGgAA1NvREqfe+fqA/vr1fh0tqbmvPcDXW7cnd9K9gxPVOSLIwxWisTQo2E2aNEkLFy7URx99pODgYNd9czabTQEBAbLZbJo4caKmTZumsLAwhYSEaMqUKUpNTa3XiFgAANB4duUXa97abC3K+lEVp6olSdEh/soYlKi7BsQptJ2fhytEY2vQdCcXOj07f/58TZgwQVLNBMWPPvqo/v73v8vpdCotLU1vvPHGBS/Fno/pTgAAuHzV1YZW7z6ieWuz9e/dR13tfTrZdN8Qu27pHSNf7watTwAPa0g2uqJ57JoCwQ4AgIY7WVGlf317SPPWZmvvkVJJkpdFSusZrYlD7EpOaM/9c61Us81jBwAAPKugqFxvr8/ROxsOqLCsUpIUZPXRHf3jNGFQouLC2nm4QjQngh0AAK3Q9h8dmrs2W0u25qqyqubiW1xYgCYMsuvn/Top2N/XwxXCEwh2AAC0ElXVhj7/vkBz12ZrY/ZxV3v/xPaaOMSum66JljfLfbVpBDsAAFq4EucpfbDpoOavy9GB42WSJB8vi0YnxWjiELuSOoV6tkC0GAQ7AABaqEMnyvTWVzl6d+NBFTtPSZJsAb66OyVeGamJirb5e7hCtDQEOwAAWpjM/Sc0b222lm7PU/XpuSs6dwjUvUPsGn9tR7Xz469v1I0jAwCAFqCyqlpLt+dr3tpsZR0sdLUP7hquiUPsuqFbpLy4fw6XQLADAMCDHGWV+vs3B/T2VznKdZRLkvy8vXRr31jdN8Suq2OY0xX1R7ADAMADso+Wav66bP0j85DKKqokSeGBfrpnYILuGZigiGCrhytEa0SwAwCgmRiGofX7jmne2myt3HlYZ9Z+6hEdrPsG2zW2b6z8fb09WyRaNYIdAABNzHmqSou35Gne2mx9l1fkah/WPUITh3TW4K7hLPeFRkGwAwCgiRwrceqdDQf016/360ixU5Lk7+ul8dd20r2D7eoaGeThCmE2BDsAABrZDwXFmrc2W4u+/VHOU9WSpKgQqzIGJequ/vFqH+jn4QphVgQ7AAAagWEYWv3DEc1dm61/7z7qak/qZNPEIXbd0jtGvt5eHqwQbQHBDgCAK1BeWaV/bf5R89Zla8/hEkmSl0UaeU20Jl5nV7+E9tw/h2ZDsAMA4DIcLirX2+v3650N+3WirFKSFGT10c/7xWnCoETFh7fzcIVoiwh2AAA0wPYfHZq3NluLt+aqsqpmvpJO7QM0YVCift4/TiH+vh6uEG0ZwQ4AgEsor6zSyu8P6+31OdqQfdzV3i+hvSYOseuma6Lkw/1zaAEIdgAA1KHiVLX+vfuIFm/J1YrvClR6enUIHy+Lbukdo4lD7OoTF+rZIoHzEOwAADjtVFW11u87piVb8rR0e56Kyk+5tnUMDdCtfWP1y9QExdgCPFglcGEEOwBAm1ZdbWjT/hNavCVXn27L07HSCte2yGCrRifFKL1PrH4SF8roVrR4BDsAQJtjGIa2HnJo8ZZcLdmap/yicte29u18Nap3jNKTYjXAHiZvL8IcWo8GB7s1a9bohRdeUGZmpvLy8rRo0SKNGzfOtX3ChAl666233F6TlpamZcuWXXGxAABcLsMwtDO/WEu25mrxljwdOF7m2hZs9VFar2il94nVoC7hTCSMVqvBwa60tFR9+vTRfffdp9tuu63OPjfffLPmz5/vem61Wi+/QgAArsC+IyVavCVPi7fmuiYQlqQAX2+NuCZK6Ukxur5bhPx9vT1YJdA4GhzsRo0apVGjRl20j9VqVXR0dL3ez+l0yul0up4XFRU1tCQAANwcPF6mT7blafGWXO3IPfv3ip+Pl27oFqH0PrEafnWk2vlxRxLMpUmO6FWrVikyMlLt27fXjTfeqGeffVbh4eF19p01a5ZmzpzZFGUAANqQw0XlrjC3+UChq93Hy6IhV3VQelKsbuoZxQTCMDWLYRjGZb/YYql1j927776rdu3ayW63a+/evXryyScVFBSk9evXy9u79mnuus7YxcXFyeFwKCQk5HJLAwC0AcdLK7R0e02Y25B9XGf+RrNYpIH2cKX3idXNvaIVFujn2UKBK1BUVCSbzVavbNToZ+zuvPNO18+9e/dWUlKSunTpolWrVmn48OG1+lutVu7BAwDUW1F5pT7bUaDFW3K1ds9RVVWfPT+RnNBe6UkxuqV3jCJD/D1YJeAZTX5zQefOndWhQwft2bOnzmAHAMCllFWc0uffH9biLblaveuIKqqqXdt6dQxRelKsRifFqFP7dh6sEvC8Jg92hw4d0rFjxxQTE9PUHwUAMJHyyiqt/qFmSa+V3x/Wycoq17aukUEa2ydWY5Ji1DkiyINVAi1Lg4NdSUmJ9uzZ43qenZ2trKwshYWFKSwsTDNnztT48eMVHR2tvXv36vHHH1fXrl2VlpbWqIUDAMynsqpa6/Yc1eItefpsR76KnWeX9EoIb6f0pFiN6ROj7lHBrAIB1KHBwW7Tpk0aNmyY6/m0adMkSRkZGZozZ462bt2qt956S4WFhYqNjdXIkSP1zDPPcB8dAKBOVdWGNmQf0+IteVq2PU8nyipd22Js/hpzekmv3h1thDngEq5oVGxTaMjIDwBA62QYhjYfKNTiLbn6ZFuejhSfnR2hQ5CfbuldE+aS49vLiyW90MZ5dFQsAAB1MQxDO3KLtHhrrpZsydOPhSdd22wBvhrVK1pjkmI1sHOYfFjSC7gsBDsAQJPaXVCsxVtytWRrnvYdLXW1B/p5a2TPaKX3idGQrhHy8yHMAVeKYAcAaHT7j5VqydaaiYN35he72q0+Xhp+daTSk2I1rEck67MCjYxgBwBoFHmOk/rkdJjbcsjhavf1tmhotwiNSYrViGuiFGTlrx6gqfCnCwBw2Y4UO7V0e56WbMnTxpzjrnYvizS4a836rGk9o2Vrx/qsQHMg2AEAGqSwrELLd+Rr8ZY8fbX3qM5Z0UsDEsOU3idGo3rHqEMQ01wBzY1gBwC4pBLnKa34Ll9LtuRpze4jqqw6m+b6xIUqPSlGo5NiFGML8GCVAAh2AIA6lVdW6YudNeuzfrHzsJynzq7P2iM6WOl9YpWeFKv4cNZnBVoKgh0AwKXiVLX+vbtmfdYV3xWotOLs+qydOwRqTJ9YpSfF6KqoYA9WCeBCCHYA0MadqqrW+n3HtGRLnpZuz1NR+dn1WTuGBtScmesTo2tiQljSC2jhCHYA0AZVVxvatP+EFm/J1afb8nSstMK1LTLYqtGn12f9SVwoYQ5oRQh2ANBGGIahrYccrlUg8ovKXdvat/PVqN4xSk+K1QB7mLxZnxVolQh2AGBihmFoZ36xlmzN1eIteTpwvMy1Ldjqo7Re0UrvE6tBXcLly/qsQKtHsAMAE9p3pESLt+Rp8dZc7Tlc4moP8PXWiGuilJ4Uo+u7RbCkF2AyBDsAMIlDJ8pc67PuyC1ytfv5eOmGbhFK7xOr4VdHqp0fv/oBs+JPNwC0YoeLyvXJtpowt/lAoavdx8uiIVfVLOl1U88ohfizpBfQFhDsAKCVOV5aoaXba8LchuzjMk4vAmGxSAPt4UrvE6ube0UrLNDPs4UCaHYEOwBoBYrKK/XZjgIt3pKrtXuOquqcBVqTE9orPSlGt/SOUWSIvwerBOBpBDsAaKHKKk5p5fc1S3qt2nVEFVVnl/Tq1TFE6UmxGp0Uo07tWdILQA2CHQC0IOWVVVr9Q82SXiu/P6yTlWeX9OoaGaSxfWI1JilGnSOCPFglgJaKYAcAHlZZVa11e45q8ZY8fbYjX8XOs0t6JYS3U3pSrMb0iVH3qGBWgQBwUQ0OdmvWrNELL7ygzMxM5eXladGiRRo3bpxru2EYmjFjhv785z+rsLBQgwcP1pw5c3TVVVc1Zt0A0KpVVRvamH1ci7fmaum2PJ0oq3Rti7H5a8zpJb16d7QR5gDUW4ODXWlpqfr06aP77rtPt912W63tzz//vF577TW99dZbstvt+u///m+lpaXpu+++k78/N/UCaLsMw9DmA4VavCVXn2zL05Fip2tbhyA/3dK7Jswlx7eXF0t6AbgMDQ52o0aN0qhRo+rcZhiGXnnlFf32t7/VrbfeKkl6++23FRUVpQ8//FB33nnnlVULAK2MYRjakVukxVtztWRLnn4sPOnaZgvw1ahe0RqTFKuBncPkw5JeAK5Qo95jl52drfz8fI0YMcLVZrPZlJKSovXr19cZ7JxOp5zOs/9qLSoqqtUHAFqb3QXFWrwlV0u25mnf0VJXe6Cft0b2jFZ6nxgN6RohPx/CHIDG06jBLj8/X5IUFRXl1h4VFeXadr5Zs2Zp5syZjVkGAHjE/mOlriW9duYXu9qtPl4afnWk0pNiNaxHJOuzAmgyHh8VO336dE2bNs31vKioSHFxcR6sCADqL89xUp+cDnNbDjlc7b7eFg3tFqExSbEacU2Ugqwe/3ULoA1o1N800dHRkqSCggLFxMS42gsKCtS3b986X2O1WmW1WhuzDABoUkeKnVq6PU9LtuRpY85xV7uXRRrctWZ91rSe0bK1Y31WAM2rUYOd3W5XdHS0Vq5c6QpyRUVF2rBhg37zm9805kcBQLNylFVq2Y48Ld6Sp6/2HtU5K3ppgD1M6UkxGtU7Rh2C+IcqAM9pcLArKSnRnj17XM+zs7OVlZWlsLAwxcfHa+rUqXr22Wd11VVXuaY7iY2NdZvrDgBagxLnKX3+Xc36rGt2H1Fl1dk01ycuVOlJMRqdFKMYW4AHqwSAsxoc7DZt2qRhw4a5np+5Py4jI0MLFizQ448/rtLSUj3wwAMqLCzUkCFDtGzZMuawA9DilVWc0ub9hdqQfUwb9h1X1sFCt/VZe0QHK71PrNKTYhUfzvqsAFoei2EYxqW7NZ+ioiLZbDY5HA6FhIR4uhwAJlZcXqlN+09ow77j2pB9TNsOOXSq2v1XYucOgRrTJ1bpSTG6KirYQ5UCaMsako0YpgWgzXCUVWpjznFt2HdMG7KPa0euQ+flOMXa/JXSOVwp9jCldA5XYng7lvQC0GoQ7ACY1rESpzZmH9eG7OP6et8x7Soo1vnXKOLD2rlCXIo9THFhXGIF0HoR7ACYxuGicn2dXXNGbmP2ce0+XFKrT+eIQKXYwzWwc5gG2MMY+ADAVAh2AFqtHwtP1lxW3XdcG3OOK/ucpbvO6B4VrJTOYUqxh2uAPUwRwUxHAsC8CHYAWgXDMHTgeJk27Duur7NrzsgdOnHSrY/FIl0TE+IKcQPsYQoL9PNQxQDQ/Ah2AFokwzC090ipNpwOcRv2HVd+UblbH28vi3p1tGng6RDXLzFMtgBWewDQdhHsALQI1dWGfjhcXHNZ9fSAh6MlTrc+vt4W9ekUqgGnBzskJ7RnDVYAOAe/EQF4RFW1oe/zirTh9GCHb3KO60RZpVsfPx8vXRsfqgH2cA20h+kn8e0V4OftoYoBoOUj2AFoFpVV1dr+o8N1Nu6bnOMqLj/l1ifA11v9EttrQGLNGbk+cTZZfQhyAFBfBDsATcJ5qkrbDjlcc8hl7j+hsooqtz5BVh/1S2yvFHu4UjqHqXdHm3y9vTxUMQC0fgQ7AI2ivLJK3x44u87q5gMn5DxV7dbHFuCr/olhGnh6+pGrY4LlQ5ADgEZDsANwWcoqTinznHVWtxx0qKLKPciFB/rVDHQ4Pdihe1SwvLxYngsAmgrBDkC9FJdXalPOCX19+ozc9h8dOnXeQquRwVbX0lwDO4epS0QQ66wCQDMi2AGoU2FZhWugw8bs49qR69B5OU4dQwNOn42rubSaEN6OIAcAHkSwAyBJOlriPD0R8DFtyD6uXQXFMs4Lcgnh7WqC3OmVHeLC2nmmWABAnQh2QBtVUFSur/cdc52V23O4pFafLhGBrkurKfZwRdv8PVApAKC+CHZAG3HoRNk5qzocU86xslp9ekQHuwY69E8MU0Sw1QOVAgAuF8EOMCHDMLT/WJk2Zh93DXb4sfCkWx8vi3RNbIjrsuqAxDC1D/TzUMUAgMZAsANMwDAM7T1Scnp5rpozcgVF7uusentZ1Luj7fRAhzD1SwxTiL+vhyoGADQFgh3QClVXG9pVUOy6rLox+7iOllS49fH1tqhvXOjpeeTClZzQXoFW/sgDgJnxWx5oBaqqDX2fV6SvT49Y/SbnuArLKt36WH28dG18+5og1zlM18a3l78v66wCQFtCsANaoMqqam3/0XH60uoxbco5oWLnKbc+7fy8lZzQ3jXYIamTTVYfghwAtGWNHuyeeuopzZw5062te/fu2rlzZ2N/FGAazlNV2nrI4ZpDLnP/CZVVVLn1Cbb6qF9ie9f0I7062uTLOqsAgHM0yRm7nj176vPPPz/7IT6cGATOVV5Zpc0Hzq6z+u2BQjlPua+zGtrOV/0Tw04vzxWuq2NC5M06qwCAi2iSxOXj46Po6Oh69XU6nXI6z47eKyoqaoqSAI8qdZ5S5v4T2nB66pEthwpVWeW+rEOHID/XQIeUzmHqFhksL4IcAKABmiTY7d69W7GxsfL391dqaqpmzZql+Pj4OvvOmjWr1qVboLUrKq/UppwzU48c17YfHao6b6HVqBCrK8Sl2MPVJSKQdVYBAFfEYhjnrwZ5ZZYuXaqSkhJ1795deXl5mjlzpn788Udt375dwcHBtfrXdcYuLi5ODodDISEhjVka0GROlFZo4+kgtzHnmL7LLdJ5OU4dQwOU0jlMA09PCJwQ3o4gBwC4pKKiItlstnplo0YPducrLCxUQkKCXnrpJU2cOPGS/RtSPOApR4qdbnPI7cwvrtUnMbyda1WHlM5h6tS+nQcqBQC0dg3JRk0+qiE0NFTdunXTnj17mvqjgCaT7yivuT/u9PQje4+U1urTNTJIKfYw131y0TZ/D1QKAGjLmjzYlZSUaO/evfrlL3/Z1B8FNJqDx8u0Ifu4Np4Oc/uPldXq0yM62DWH3AB7mDoEWT1QKQAAZzV6sPu///f/Kj09XQkJCcrNzdWMGTPk7e2tu+66q7E/CrhilVXVOni8TDnHSrXvSKm+yy3Shuzj+rHwpFs/L4vUM9Z2+mxczVm50HZ+HqoaAIC6NXqwO3TokO666y4dO3ZMERERGjJkiL7++mtFREQ09kcB9VJdbSivqFzZR0qVfay05r9HS5RzrEwHjpfVGq0qST5eFvXuVBPkBtrDlZzYXiH+vh6oHgCA+mv0YPfuu+829lsCl2QYho6VVij7aOl5Aa5UOcdKa03+e64AX2/ZOwTK3iFQXSKD1D+xva6Nb69AKxNrAwBaF/7mQqtSVF6pnKM1gW3fkZrQdibMnb+W6rl8vS2KD2sne4cg2Tuc+W9NmIsKsTLtCADAFAh2aHHKK6uUc6xUOUdLte90aDsT4I6WVFzwdRZLzVxx9g6B6twhUImng1vnDkGKDfWXD+uqAgBMjmAHj6isqtahEyeVfbRE2UfLTv+3VDlHy2oNXDhfZLBViafDm/10gOvcIVBxYe3k7+vdTN8AAICWh2CHJnNm0EJdZ94OHi/TqToGLZwR4u+jzhFnL5fazwlxQdz7BgBAnfgbElfEbdDC0bP3u50JcJcatJDoumzqft9b+3a+3PcGAEADEexQL+cOWjj/UVx+8UELcWHt3C6bnrnvjUELAAA0LoIdXMorq7T/WM39bvuOlroFufoOWrCfd99bx9AABi0AANBMCHZtzJlBC6773o6WKOdombKPlirXcVLGhW97U0SwtSa4hQfKHnE2xMUzaAEAgBaBYGdC1dWG8ovKa10yzTlaqgP1GLRgjwique/tdIDr3CFQCeHtFMzKCwAAtGgEu1bqzKCFs2fezl46zTlWqvLKCw9a8Pf1UmJ4oDqfPut29ucgBi0AANCKEexauLoGLZwJcxcbtODjZVF8eLuay6YdTl86PX0GLirYX15ehDcAAMyGYNcCnDto4dzJerOPluloifOCr7NYpFhbQK253uwdAtWpPYMWAABoawh2zeSUa6WF0lojTi81aKFDkLXOud4Swhm0AAAAziLYNaIzgxbquu/tUoMWgv19XHO92TsEKbFDO3U+/V8GLQAAgPog2DWQYRg6fv5KCw0ctHD+XG/2DoEKC/Rj0AIAALgiBLsLKC6vVM7RMu1zzfNW4gpwRZcatBDWzrXCwrmP6BAGLQAAgKbTpoNdeWWVDhwv074j7pdN9x0tveigBensSgtn7nvrfPoMXKf2AfJl0AIAAPCANhvs/r37iH41b+MlBi341XHZNIhBCwAAoEVqs8GuY2iADEMKtvq4LY91bpALYdACAABoRdpssEsID9Sm345QOIMWAACASbTZYOftZVGHIKunywAAAGg0TXaX/+zZs5WYmCh/f3+lpKRo48aNTfVRAAAAUBMFu/fee0/Tpk3TjBkztHnzZvXp00dpaWk6fPhwU3wcAAAAJFkM42LjQi9PSkqK+vfvr9dff12SVF1drbi4OE2ZMkVPPPGEW1+n0ymn8+zUIkVFRYqLi5PD4VBISEhjlwYAANCqFBUVyWaz1SsbNfoZu4qKCmVmZmrEiBFnP8TLSyNGjND69etr9Z81a5ZsNpvrERcX19glAQAAtAmNPnji6NGjqqqqUlRUlFt7VFSUdu7cWav/9OnTNW3aNNdzh8Oh+Ph4FRUVNXZpAAAArc6ZTFSfi6weHxVrtVpltZ4dnXqmeM7cAQAAnFVcXCybzXbRPo0e7Dp06CBvb28VFBS4tRcUFCg6OvqSr4+NjdXBgwcVHBzc5PPLnbmf7+DBg236fj72Qw32Qw32w1nsixrshxrshxrsh7Oaa18YhqHi4mLFxsZesm+jBzs/Pz8lJydr5cqVGjdunKSawRMrV67U5MmTL/l6Ly8vderUqbHLuqiQkJA2f3BK7Icz2A812A9nsS9qsB9qsB9qsB/Oao59cakzdWc0yaXYadOmKSMjQ/369dOAAQP0yiuvqLS0VPfee29TfBwAAADURMHujjvu0JEjR/S73/1O+fn56tu3r5YtW1ZrQAUAAAAaT5MNnpg8eXK9Lr16ktVq1YwZM9wGb7RF7Ica7Ica7Iez2Bc12A812A812A9ntcR90SQTFAMAAKD5NdlasQAAAGheBDsAAACTINgBAACYBMEOAADAJEwb7NasWaP09HTFxsbKYrHoww8/vORrVq1apWuvvVZWq1Vdu3bVggULmrzO5tDQfbFq1SpZLJZaj/z8/OYpuAnMmjVL/fv3V3BwsCIjIzVu3Djt2rXrkq/74IMP1KNHD/n7+6t379769NNPm6HapnU5+2LBggW1jgd/f/9mqrhpzJkzR0lJSa6JRVNTU7V06dKLvsaMx0ND94MZj4W6PPfcc7JYLJo6depF+5nxmDhXffaDWY+Jp556qtb36tGjx0Vf0xKOB9MGu9LSUvXp00ezZ8+uV//s7GyNHj1aw4YNU1ZWlqZOnar7779fy5cvb+JKm15D98UZu3btUl5enusRGRnZRBU2vdWrV2vSpEn6+uuvtWLFClVWVmrkyJEqLS294Gu++uor3XXXXZo4caK+/fZbjRs3TuPGjdP27dubsfLGdzn7QqqZWf3c42H//v3NVHHT6NSpk5577jllZmZq06ZNuvHGG3Xrrbdqx44ddfY36/HQ0P0gme9YON8333yjN998U0lJSRftZ9Zj4oz67gfJvMdEz5493b7X2rVrL9i3xRwPRhsgyVi0aNFF+zz++ONGz5493druuOMOIy0trQkra3712RdffvmlIck4ceJEs9TkCYcPHzYkGatXr75gn5///OfG6NGj3dpSUlKMBx98sKnLa1b12Rfz5883bDZb8xXlIe3btzf+8pe/1LmtrRwPhnHx/WD2Y6G4uNi46qqrjBUrVhhDhw41Hn744Qv2NfMx0ZD9YNZjYsaMGUafPn3q3b+lHA+mPWPXUOvXr9eIESPc2tLS0rR+/XoPVeR5ffv2VUxMjG666SatW7fO0+U0KofDIUkKCwu7YJ+2ckzUZ19IUklJiRISEhQXF3fJMzqtTVVVld59912VlpYqNTW1zj5t4Xioz36QzH0sTJo0SaNHj671/7ouZj4mGrIfJPMeE7t371ZsbKw6d+6sX/ziFzpw4MAF+7aU46HJVp5obfLz82steRYVFaWioiKdPHlSAQEBHqqs+cXExOhPf/qT+vXrJ6fTqb/85S+64YYbtGHDBl177bWeLu+KVVdXa+rUqRo8eLB69ep1wX4XOiZa872G56vvvujevbvmzZunpKQkORwOvfjiixo0aJB27NihTp06NWPFjWvbtm1KTU1VeXm5goKCtGjRIl1zzTV19jXz8dCQ/WDWY0GS3n33XW3evFnffPNNvfqb9Zho6H4w6zGRkpKiBQsWqHv37srLy9PMmTN13XXXafv27QoODq7Vv6UcDwQ71NK9e3d1797d9XzQoEHau3evXn75Zf31r3/1YGWNY9KkSdq+fftF75VoK+q7L1JTU93O4AwaNEhXX3213nzzTT3zzDNNXWaT6d69u7KysuRwOPSPf/xDGRkZWr169QVDjVk1ZD+Y9Vg4ePCgHn74Ya1YscIUN/5frsvZD2Y9JkaNGuX6OSkpSSkpKUpISND777+viRMnerCyiyPYnRYdHa2CggK3toKCAoWEhLSps3UXMmDAAFMEocmTJ2vJkiVas2bNJf8leaFjIjo6uilLbDYN2Rfn8/X11U9+8hPt2bOniaprHn5+furataskKTk5Wd98841effVVvfnmm7X6mvl4aMh+OJ9ZjoXMzEwdPnzY7apEVVWV1qxZo9dff11Op1Pe3t5urzHjMXE5++F8ZjkmzhcaGqpu3bpd8Hu1lOOBe+xOS01N1cqVK93aVqxYcdH7TNqSrKwsxcTEeLqMy2YYhiZPnqxFixbpiy++kN1uv+RrzHpMXM6+OF9VVZW2bdvWqo+JulRXV8vpdNa5zazHQ10uth/OZ5ZjYfjw4dq2bZuysrJcj379+ukXv/iFsrKy6gwzZjwmLmc/nM8sx8T5SkpKtHfv3gt+rxZzPDTrUI1mVFxcbHz77bfGt99+a0gyXnrpJePbb7819u/fbxiGYTzxxBPGL3/5S1f/ffv2Ge3atTMee+wx4/vvvzdmz55teHt7G8uWLfPUV2g0Dd0XL7/8svHhhx8au3fvNrZt22Y8/PDDhpeXl/H555976itcsd/85jeGzWYzVq1aZeTl5bkeZWVlrj6//OUvjSeeeML1fN26dYaPj4/x4osvGt9//70xY8YMw9fX19i2bZsnvkKjuZx9MXPmTGP58uXG3r17jczMTOPOO+80/P39jR07dnjiKzSKJ554wli9erWRnZ1tbN261XjiiScMi8VifPbZZ4ZhtJ3joaH7wYzHwoWcPxq0rRwT57vUfjDrMfHoo48aq1atMrKzs41169YZI0aMMDp06GAcPnzYMIyWezyYNtidmbLj/EdGRoZhGIaRkZFhDB06tNZr+vbta/j5+RmdO3c25s+f3+x1N4WG7os//OEPRpcuXQx/f38jLCzMuOGGG4wvvvjCM8U3krq+vyS3/8dDhw517ZMz3n//faNbt26Gn5+f0bNnT+OTTz5p3sKbwOXsi6lTpxrx8fGGn5+fERUVZdxyyy3G5s2bm7/4RnTfffcZCQkJhp+fnxEREWEMHz7cFWYMo+0cDw3dD2Y8Fi7k/EDTVo6J811qP5j1mLjjjjuMmJgYw8/Pz+jYsaNxxx13GHv27HFtb6nHg8UwDKP5zg8CAACgqXCPHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7ACgEU2YMEGJiYmeLgNAG0WwA9CiLViwQBaLxe0RGRmpYcOGaenSpc1Wxw033OBWQ1hYmPr376958+apurq6UT7j97//vT788MNGeS8AbZOPpwsAgPp4+umnZbfbZRiGCgoKtGDBAt1yyy1avHixxowZ0yw1dOrUSbNmzZIkHTlyRG+//bYmTpyoH374Qc8999wVv//vf/973X777Ro3btwVvxeAtolgB6BVGDVqlPr16+d6PnHiREVFRenvf/97owS76upqVVRUyN/f/4J9bDab7rnnHtfzBx98UN27d9frr7+uZ555Rr6+vldcBwBcCS7FAmiVQkNDFRAQIB8f93+fvvjiixo0aJDCw8MVEBCg5ORk/eMf/6j1eovFosmTJ+udd95Rz549ZbVatWzZsgbV0K5dOw0cOFClpaU6cuTIBfuVlpbq0UcfVVxcnKxWq7p3764XX3xRhmG41VNaWqq33nrLdbl3woQJDaoHADhjB6BVcDgcOnr0qAzD0OHDh/U///M/KikpcTuDJkmvvvqqxo4dq1/84heqqKjQu+++q5/97GdasmSJRo8e7db3iy++0Pvvv6/JkyerQ4cOlzXoYd++ffL29lZoaGid2w3D0NixY/Xll19q4sSJ6tu3r5YvX67HHntMP/74o15++WVJ0l//+lfdf//9GjBggB544AFJUpcuXRpcD4A2zgCAFmz+/PmGpFoPq9VqLFiwoFb/srIyt+cVFRVGr169jBtvvNGtXZLh5eVl7Nixo151DB061OjRo4dx5MgR48iRI8b3339vPPTQQ4YkIz093dUvIyPDSEhIcD3/8MMPDUnGs88+6/Z+t99+u2GxWIw9e/a42gIDA42MjIx61QMAdeGMHYBWYfbs2erWrZskqaCgQH/72990//33Kzg4WLfddpurX0BAgOvnEydOqKqqStddd53+/ve/13rPoUOH6pprrql3DTt37lRERITrucVi0ejRozVv3rwLvubTTz+Vt7e3HnroIbf2Rx99VP/4xz+0dOlSTZ48ud41AMDFEOwAtAoDBgxwGzxx11136Sc/+YkmT56sMWPGyM/PT5K0ZMkSPfvss8rKypLT6XT1t1gstd7Tbrc3qIbExET9+c9/lsVikb+/v6666ipFRkZe9DX79+9XbGysgoOD3dqvvvpq13YAaCwMngDQKnl5eWnYsGHKy8vT7t27JUn//ve/NXbsWPn7++uNN97Qp59+qhUrVujuu+92G6hwxrln9+ojMDBQI0aM0PDhwzV48OBLhjoAaG6csQPQap06dUqSVFJSIkn65z//KX9/fy1fvlxWq9XVb/78+R6pT5ISEhL0+eefq7i42O2s3c6dO13bz6jrrCIANARn7AC0SpWVlfrss8/k5+fnuqzp7e0ti8WiqqoqV7+cnByPruZwyy23qKqqSq+//rpb+8svvyyLxaJRo0a52gIDA1VYWNjMFQIwE87YAWgVli5d6jrLdfjwYS1cuFC7d+/WE088oZCQEEnS6NGj9dJLL+nmm2/W3XffrcOHD2v27Nnq2rWrtm7d6pG609PTNWzYMP3Xf/2XcnJy1KdPH3322Wf66KOPNHXqVLcpTZKTk/X555/rpZdeUmxsrOx2u1JSUjxSN4DWiWAHoFX43e9+5/rZ399fPXr00Jw5c/Tggw+62m+88UbNnTtXzz33nKZOnSq73a4//OEPysnJ8Viw8/Ly0scff6zf/e53eu+99zR//nwlJibqhRde0KOPPurW96WXXtIDDzyg3/72tzp58qQyMjIIdgAaxGLUdUcxAAAAWh3usQMAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ7AAAAkyDYAQAAmESLm8euurpaubm5Cg4OZnkdAADQ5hmGoeLiYsXGxsrL6+Ln5FpcsMvNzVVcXJynywAAAGhRDh48qE6dOl20T4sLdmcWyT548KBrmSAAAIC2qqioSHFxca6MdDEtLtidufwaEhJCsAMAADitPreoMXgCAADAJBoU7ObMmaOkpCTX2bTU1FQtXbrUtb28vFyTJk1SeHi4goKCNH78eBUUFDR60QAAAKitQcGuU6dOeu6555SZmalNmzbpxhtv1K233qodO3ZIkh555BEtXrxYH3zwgVavXq3c3FzddtttTVI4AAAA3FkMwzCu5A3CwsL0wgsv6Pbbb1dERIQWLlyo22+/XZK0c+dOXX311Vq/fr0GDhxYr/crKiqSzWaTw+HgHjsAANDmNSQbXfY9dlVVVXr33XdVWlqq1NRUZWZmqrKyUiNGjHD16dGjh+Lj47V+/foLvo/T6VRRUZHbAwAAAA3X4FGx27ZtU2pqqsrLyxUUFKRFixbpmmuuUVZWlvz8/BQaGurWPyoqSvn5+Rd8v1mzZmnmzJkNLhwAgPpIfOITT5cAE8t5brSnS3DT4DN23bt3V1ZWljZs2KDf/OY3ysjI0HfffXfZBUyfPl0Oh8P1OHjw4GW/FwAAQFvW4DN2fn5+6tq1qyQpOTlZ33zzjV599VXdcccdqqioUGFhodtZu4KCAkVHR1/w/axWq6xWa8MrBwAAgJsrnseuurpaTqdTycnJ8vX11cqVK13bdu3apQMHDig1NfVKPwYAAACX0KAzdtOnT9eoUaMUHx+v4uJiLVy4UKtWrdLy5ctls9k0ceJETZs2TWFhYQoJCdGUKVOUmppa7xGxAAAAuHwNCnaHDx/Wr371K+Xl5clmsykpKUnLly/XTTfdJEl6+eWX5eXlpfHjx8vpdCotLU1vvPFGkxQOAAAAd1c8j11jYx47AEBjYlQsmlJzjIptlnnsAAAA0LIQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTINgBAACYBMEOAADAJAh2AAAAJkGwAwAAMAmCHQAAgEkQ7AAAAEyCYAcAAGASBDsAAACTaFCwmzVrlvr376/g4GBFRkZq3Lhx2rVrl1uf8vJyTZo0SeHh4QoKCtL48eNVUFDQqEUDAACgtgYFu9WrV2vSpEn6+uuvtWLFClVWVmrkyJEqLS119XnkkUe0ePFiffDBB1q9erVyc3N12223NXrhAAAAcOfTkM7Lli1ze75gwQJFRkYqMzNT119/vRwOh+bOnauFCxfqxhtvlCTNnz9fV199tb7++msNHDiw1ns6nU45nU7X86Kiosv5HgAAAG1eg4Ld+RwOhyQpLCxMkpSZmanKykqNGDHC1adHjx6Kj4/X+vXr6wx2s2bN0syZM6+kDAANkPjEJ54uASaV89xoT5cAtHmXPXiiurpaU6dO1eDBg9WrVy9JUn5+vvz8/BQaGurWNyoqSvn5+XW+z/Tp0+VwOFyPgwcPXm5JAAAAbdpln7GbNGmStm/frrVr115RAVarVVar9YreAwAAAJd5xm7y5MlasmSJvvzyS3Xq1MnVHh0drYqKChUWFrr1LygoUHR09BUVCgAAgItrULAzDEOTJ0/WokWL9MUXX8hut7ttT05Olq+vr1auXOlq27Vrlw4cOKDU1NTGqRgAAAB1atCl2EmTJmnhwoX66KOPFBwc7LpvzmazKSAgQDabTRMnTtS0adMUFhamkJAQTZkyRampqXUOnAAAAEDjaVCwmzNnjiTphhtucGufP3++JkyYIEl6+eWX5eXlpfHjx8vpdCotLU1vvPFGoxQLAACAC2tQsDMM45J9/P39NXv2bM2ePfuyiwIAAEDDsVYsAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBINDnZr1qxRenq6YmNjZbFY9OGHH7ptNwxDv/vd7xQTE6OAgACNGDFCu3fvbqx6AQAAcAENDnalpaXq06ePZs+eXef2559/Xq+99pr+9Kc/acOGDQoMDFRaWprKy8uvuFgAAABcmE9DXzBq1CiNGjWqzm2GYeiVV17Rb3/7W916662SpLfffltRUVH68MMPdeedd15ZtQAAALigRr3HLjs7W/n5+RoxYoSrzWazKSUlRevXr6/zNU6nU0VFRW4PAAAANFyDz9hdTH5+viQpKirKrT0qKsq17XyzZs3SzJkzG7OMBkl84hOPfTbMLee50Z4uAQDQxnh8VOz06dPlcDhcj4MHD3q6JAAAgFapUYNddHS0JKmgoMCtvaCgwLXtfFarVSEhIW4PAAAANFyjBju73a7o6GitXLnS1VZUVKQNGzYoNTW1MT8KAAAA52nwPXYlJSXas2eP63l2draysrIUFham+Ph4TZ06Vc8++6yuuuoq2e12/fd//7diY2M1bty4xqwbAAAA52lwsNu0aZOGDRvmej5t2jRJUkZGhhYsWKDHH39cpaWleuCBB1RYWKghQ4Zo2bJl8vf3b7yqAQAAUEuDg90NN9wgwzAuuN1isejpp5/W008/fUWFAQAAoGE8PioWAAAAjYNgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJhEkwW72bNnKzExUf7+/kpJSdHGjRub6qMAAACgJgp27733nqZNm6YZM2Zo8+bN6tOnj9LS0nT48OGm+DgAAABI8mmKN33ppZf061//Wvfee68k6U9/+pM++eQTzZs3T0888YRbX6fTKafT6XrucDgkSUVFRU1RWi3VzrJm+Ry0Pc11DDcUxzyaCsc82qLmOO7PfIZhGJfubDQyp9NpeHt7G4sWLXJr/9WvfmWMHTu2Vv8ZM2YYknjw4MGDBw8ePHhc5HHw4MFL5rBGP2N39OhRVVVVKSoqyq09KipKO3furNV/+vTpmjZtmut5dXW1jh8/rvDwcFkslsYuD1egqKhIcXFxOnjwoEJCQjxdDtDkOObR1nDMt0yGYai4uFixsbGX7Nskl2Ibwmq1ymq1urWFhoZ6phjUS0hICH/g0aZwzKOt4ZhveWw2W736NfrgiQ4dOsjb21sFBQVu7QUFBYqOjm7sjwMAAMBpjR7s/Pz8lJycrJUrV7raqqurtXLlSqWmpjb2xwEAAOC0JrkUO23aNGVkZKhfv34aMGCAXnnlFZWWlrpGyaJ1slqtmjFjRq1L54BZccyjreGYb/0shlGfsbMN9/rrr+uFF15Qfn6++vbtq9dee00pKSlN8VEAAABQEwY7AAAANC/WigUAADAJgh0AAIBJEOwAAABMgmAHAABgEgQ71Mv69evl7e2t0aNHe7oUoElNmDBBFovF9QgPD9fNN9+srVu3ero0oEnl5+drypQp6ty5s6xWq+Li4pSenu42Ly1aPoId6mXu3LmaMmWK1qxZo9zcXE+XAzSpm2++WXl5ecrLy9PKlSvl4+OjMWPGeLosoMnk5OQoOTlZX3zxhV544QVt27ZNy5Yt07BhwzRp0iRPl4cGYLoTXFJJSYliYmK0adMmzZgxQ0lJSXryySc9XRbQJCZMmKDCwkJ9+OGHrra1a9fquuuu0+HDhxUREeG54oAmcsstt2jr1q3atWuXAgMD3bYVFhayhnsrwhk7XNL777+vHj16qHv37rrnnns0b9488e8BtBUlJSX629/+pq5duyo8PNzT5QCN7vjx41q2bJkmTZpUK9RJItS1Mk2ypBjMZe7cubrnnnsk1VyicjgcWr16tW644QbPFgY0kSVLligoKEiSVFpaqpiYGC1ZskReXvxbGOazZ88eGYahHj16eLoUNAJ+S+Gidu3apY0bN+quu+6SJPn4+OiOO+7Q3LlzPVwZ0HSGDRumrKwsZWVlaePGjUpLS9OoUaO0f/9+T5cGNDquwJgLZ+xwUXPnztWpU6cUGxvrajMMQ1arVa+//rpsNpsHqwOaRmBgoLp27ep6/pe//EU2m01//vOf9eyzz3qwMqDxXXXVVbJYLNq5c6enS0Ej4IwdLujUqVN6++239cc//tF19iIrK0tbtmxRbGys/v73v3u6RKBZWCwWeXl56eTJk54uBWh0YWFhSktL0+zZs1VaWlpre2FhYfMXhctGsMMFLVmyRCdOnNDEiRPVq1cvt8f48eO5HAvTcjqdys/PV35+vr7//ntNmTJFJSUlSk9P93RpQJOYPXu2qqqqNGDAAP3zn//U7t279f333+u1115Tamqqp8tDAxDscEFz587ViBEj6rzcOn78eG3atIlJW2FKy5YtU0xMjGJiYpSSkqJvvvlGH3zwAQOGYFqdO3fW5s2bNWzYMD366KPq1auXbrrpJq1cuVJz5szxdHloAOaxAwAAMAnO2AEAAJgEwQ4AAMAkCHYAAAAmQbADAAAwCYIdAACASRDsAAAATIJgBwAAYBIEOwAAAJMg2AEAAJgEwQ4AAMAkCHYAAAAm8f8BRBQxA65aZeUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "# Create a line plot on the first subplot\n",
    "axs[0].plot([1, 2, 3, 4, 5], [1, 4, 9, 16, 25])\n",
    "axs[0].set_title('Square Numbers')\n",
    "\n",
    "# Create a bar plot on the second subplot\n",
    "axs[1].bar(['A', 'B', 'C'], [10, 20, 30])\n",
    "axs[1].set_title('Bar Plot')\n",
    "\n",
    "# Display the figure and its subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# Create a FacetGrid with one column for each species\n",
    "g = sns.FacetGrid(iris, col=\"species\")\n",
    "\n",
    "# Map histograms of sepal length to each subplot\n",
    "g.map(plt.hist, \"sepal_length\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the plot style to 'whitegrid'\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create a scatter plot with a regression line\n",
    "df = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5],\n",
    "    'y': [1, 4, 9, 16, 25]\n",
    "})\n",
    "sns.regplot(x='x', y='y', data=df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection, linear_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Create a StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler to the data\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler.fit(data)\n",
    "\n",
    "# Transform the data\n",
    "scaled_data = scaler.transform(data)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create a linear regression model\n",
    "model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create a linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "X_new = [[2, 2]]\n",
    "y_new = model.predict(X_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Calculate the mean squared error of the predictions\n",
    "y_true = [1]\n",
    "y_pred = model.predict(X_new)\n",
    "mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create a linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=2)\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the dataset\n",
    "X = [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4]]\n",
    "y = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Create a linear regression model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  NaN  8\n",
      "2  NaN  6.0  9\n",
      "\n",
      "DataFrame after dropping rows with missing values:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "\n",
      "DataFrame after filling missing values with 0:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  0.0  8\n",
      "2  0.0  6.0  9\n",
      "\n",
      "DataFrame after filling missing values with mean of the column:\n",
      "     A    B  C\n",
      "0  1.0  4.0  7\n",
      "1  2.0  5.0  8\n",
      "2  1.5  6.0  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with missing values\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan],\n",
    "    'B': [4, np.nan, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Remove rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\")\n",
    "print(df_dropped)\n",
    "\n",
    "# Fill missing values with a specific value\n",
    "df_filled = df.fillna(0)\n",
    "print(\"\\nDataFrame after filling missing values with 0:\")\n",
    "print(df_filled)\n",
    "\n",
    "# Fill missing values with mean of the column\n",
    "df_filled_mean = df.fillna(df.mean())\n",
    "print(\"\\nDataFrame after filling missing values with mean of the column:\")\n",
    "print(df_filled_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  2  5  8\n",
      "3  3  6  9\n",
      "4  3  6  9\n",
      "5  3  6  9\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "3  3  6  9\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 3, 3],\n",
    "    'B': [4, 5, 5, 6, 6, 6],\n",
    "    'C': [7, 8, 8, 9, 9, 9]\n",
    "})\n",
    "print(df)\n",
    "newdf=df.drop_duplicates()\n",
    "print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 3 1 2 3 3 4 4 4]\n",
      "[False False False False False False False False False False False False\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Create a numpy array with outliers\n",
    "data = np.array([1, 2, 2, 2, 3, 1, 2, 3, 3, 4, 4, 4, 20])\n",
    "\n",
    "z=stats.zscore(data)\n",
    "outliers=np.abs(z)>2\n",
    "data_clean=data[~outliers]\n",
    "\n",
    "print(data_clean)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height  width   area\n",
      "0     5.0    3.5  17.50\n",
      "1     6.1    3.0  18.30\n",
      "2     5.6    3.2  17.92\n",
      "3     5.8    3.7  21.46\n",
      "4     6.0    3.3  19.80\n"
     ]
    }
   ],
   "source": [
    "#feature engineering\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'height': [5.0, 6.1, 5.6, 5.8, 6.0],\n",
    "    'width': [3.5, 3.0, 3.2, 3.7, 3.3]\n",
    "})\n",
    "\n",
    "df['area']=df['height']*df['width'] #new interaction feature created\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.    5.    3.5  25.   17.5  12.25]\n",
      " [ 1.    6.1   3.   37.21 18.3   9.  ]\n",
      " [ 1.    5.6   3.2  31.36 17.92 10.24]\n",
      " [ 1.    5.8   3.7  33.64 21.46 13.69]\n",
      " [ 1.    6.    3.3  36.   19.8  10.89]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'height': [5.0, 6.1, 5.6, 5.8, 6.0],\n",
    "    'width': [3.5, 3.0, 3.2, 3.7, 3.3]\n",
    "})\n",
    "\n",
    "# Extract numerical features from the DataFrame\n",
    "X = df[['height', 'width']]\n",
    "\n",
    "# Create a PolynomialFeatures object\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "# Create polynomial features\n",
    "df_poly = poly.fit_transform(X)\n",
    "\n",
    "print(df_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          child\n",
      "1          child\n",
      "2    young adult\n",
      "3    young adult\n",
      "4          adult\n",
      "5         senior\n",
      "Name: age, dtype: category\n",
      "Categories (4, object): ['child' < 'young adult' < 'adult' < 'senior']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'age': [5, 15, 25, 35, 45, 65]\n",
    "})\n",
    "\n",
    "# Define bins\n",
    "bins = [0, 18, 35, 60, 100]\n",
    "\n",
    "# Define labels\n",
    "labels = ['child', 'young adult', 'adult', 'senior']\n",
    "df=pd.cut(df['age'],bins=bins,labels=labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B\n",
      "0  0.00  0.00\n",
      "1  0.25  0.25\n",
      "2  0.50  0.50\n",
      "3  0.75  0.75\n",
      "4  1.00  1.00\n"
     ]
    }
   ],
   "source": [
    "#normalization in scikit learn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50]\n",
    "})\n",
    "scaler=MinMaxScaler()\n",
    "df_normalized=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B\n",
      "0 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107\n",
      "2  0.000000  0.000000\n",
      "3  0.707107  0.707107\n",
      "4  1.414214  1.414214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.118034</td>\n",
       "      <td>1.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B\n",
       "count  5.000000  5.000000\n",
       "mean   0.000000  0.000000\n",
       "std    1.118034  1.118034\n",
       "min   -1.414214 -1.414214\n",
       "25%   -0.707107 -0.707107\n",
       "50%    0.000000  0.000000\n",
       "75%    0.707107  0.707107\n",
       "max    1.414214  1.414214"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50]\n",
    "})\n",
    "scaler=StandardScaler()\n",
    "df_stds=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\n",
    "print(df_stds)\n",
    "df_stds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 2 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a list of categories\n",
    "categories = ['red', 'blue', 'green', 'red', 'green', 'blue', 'blue', 'green']\n",
    "\n",
    "# Create a LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Perform Label Encoding\n",
    "encoded_categories = encoder.fit_transform(categories)\n",
    "\n",
    "print(encoded_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a list of categories\n",
    "categories = [['red'], ['blue'], ['green'], ['red'], ['green'], ['blue'], ['blue'], ['green']]\n",
    "\n",
    "# Create a OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Perform One-Hot Encoding\n",
    "onehot_encoded_categories = encoder.fit_transform(categories)\n",
    "\n",
    "print(onehot_encoded_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Create a list of categories\n",
    "categories = [['cold'], ['warm'], ['hot'], ['cold'], ['hot'], ['warm'], ['warm'], ['hot']]\n",
    "encoder=OrdinalEncoder(categories=[['cold','warm','hot']])\n",
    "new=encoder.fit_transform(categories)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B\n",
      "0  0.00  0.00\n",
      "1  0.25  0.25\n",
      "2  0.50  0.50\n",
      "3  0.75  0.75\n",
      "4  1.00  1.00\n"
     ]
    }
   ],
   "source": [
    "#Standardization\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50]\n",
    "})\n",
    "scaler=MinMaxScaler()\n",
    "new=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B\n",
      "0 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107\n",
      "2  0.000000  0.000000\n",
      "3  0.707107  0.707107\n",
      "4  1.414214  1.414214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.118034</td>\n",
       "      <td>1.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B\n",
       "count  5.000000  5.000000\n",
       "mean   0.000000  0.000000\n",
       "std    1.118034  1.118034\n",
       "min   -1.414214 -1.414214\n",
       "25%   -0.707107 -0.707107\n",
       "50%    0.000000  0.000000\n",
       "75%    0.707107  0.707107\n",
       "max    1.414214  1.414214"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50]\n",
    "})\n",
    "scaler=StandardScaler()\n",
    "new=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\n",
    "print(new)\n",
    "new.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "    A    B\n",
      "5   6   60\n",
      "0   1   10\n",
      "7   8   80\n",
      "2   3   30\n",
      "9  10  100\n",
      "4   5   50\n",
      "3   4   40\n",
      "6   7   70\n",
      "\n",
      "X_test:\n",
      "   A   B\n",
      "8  9  90\n",
      "1  2  20\n",
      "\n",
      "y_train:\n",
      "[1, 0, 1, 0, 1, 0, 0, 1]\n",
      "\n",
      "y_test:\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "})\n",
    "\n",
    "# Create a target variable\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "X_train, X_test, y_train,y_test=train_test_split(df,y,test_size=0.2,random_state=42)\n",
    "print(\"X_train:\")\n",
    "print(X_train)\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test)\n",
    "print(\"\\ny_train:\")\n",
    "print(y_train)\n",
    "print(\"\\ny_test:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 1]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "})\n",
    "\n",
    "# Create a target variable with imbalanced class distribution\n",
    "y = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "X_train,X_test,y_train,y_test=train_test_split(df,y,random_state=42,test_size=0.2,stratify=y)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A    B    C\n",
       "0  1.000000  4.5  5.0\n",
       "1  2.000000  2.0  5.0\n",
       "2  4.166667  3.0  3.0\n",
       "3  4.000000  4.0  4.0\n",
       "4  5.000000  5.0  5.0\n",
       "5  6.000000  6.0  6.0\n",
       "6  7.000000  7.0  7.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#exercises(preprocessing)\n",
    "df=pd.DataFrame({\n",
    "    'A':[1,2,np.nan,4,5,6,7],\n",
    "    'B':[np.nan,2,3,4,5,6,7],\n",
    "    'C':[np.nan,np.nan,3,4,5,6,7]\n",
    "})\n",
    "#fill these empty values\n",
    "#df.dropna()\n",
    "df.fillna(df.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C    D\n",
       "0  1  2  3    6\n",
       "1  2  3  4   24\n",
       "2  3  4  5   60\n",
       "3  4  5  6  120\n",
       "4  5  6  7  210"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\n",
    "    'A':[1,2,3,4,5],\n",
    "    'B':[2,3,4,5,6],\n",
    "    'C':[3,4,5,6,7]\n",
    "})\n",
    "\n",
    "df['D']=df['A']*df['B']*df['C']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "['color_blue' 'color_green' 'color_red']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df=pd.DataFrame({\n",
    "    'color':['red','blue','green','red']\n",
    "})\n",
    "encoder=OneHotEncoder(sparse_output=False)\n",
    "encoded=encoder.fit_transform(df)\n",
    "print(encoded)\n",
    "names=encoder.get_feature_names_out()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.8, 3.4, 4. , 4.6, 5.2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple linear regression   \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [2, 4, 5, 4, 5]\n",
    "})\n",
    "model=LinearRegression()\n",
    "model.fit(df[['A']],df['B'])#double square brackets at df[['A']] because even df[['A','B']] can be inputted\n",
    "model.predict(df[['A']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "#multi linear regression\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [2, 3, 4, 5, 6],\n",
    "    'C': [3, 4, 5, 6, 7]\n",
    "})\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(df[['A','B']],df['C'])\n",
    "preds=model.predict(df[['A','B']])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6399999999999999\n",
      "0.47999999999999987\n",
      "0.6928203230275508\n",
      "0.17621623900396277\n",
      "0.33333333333333326\n"
     ]
    }
   ],
   "source": [
    "#evaluation metrics\n",
    "#mse,mae,mape,rmse  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error,r2_score\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [2, 4, 5, 4, 5]\n",
    "})\n",
    "model=LinearRegression()\n",
    "model.fit(df[['A']],df['B'])\n",
    "pred=model.predict(df[['A']])\n",
    "\n",
    "mae=mean_absolute_error(pred,df['B'])\n",
    "mse=mean_squared_error(pred,df['B'])\n",
    "rmse=np.sqrt(mse)\n",
    "mape=mean_absolute_percentage_error(pred,df['B'])\n",
    "rsq=r2_score(pred,df['B'])\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)\n",
    "print(mape)\n",
    "print(rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [0, 0, 0, 1, 1]\n",
    "})\n",
    "\n",
    "model=LogisticRegression()\n",
    "model.fit(df[['A']],df['B'])\n",
    "print(model.predict(df[['A']]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decision tree\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [0, 0, 0, 1, 1]\n",
    "})\n",
    "model=DecisionTreeClassifier()\n",
    "model.fit(df[['A']],df['B'])\n",
    "model.predict(df[['A']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#support vector machine\n",
    "from sklearn import svm\n",
    "clf=svm.SVC(kernel='linear')\n",
    "clf.fit(df[['A']],df['B'])\n",
    "clf.predict(df[['A']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model=KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(df[['A']],df['B'])\n",
    "pred=model.predict(df[['A']])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(df[['A']],df['B'])\n",
    "model.predict(df[['A']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradientbooster\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model=GradientBoostingClassifier(n_estimators=100,learning_rate=1.0,max_depth=1,random_state=0)\n",
    "model.fit(df[['A']],df['B'])\n",
    "model.predict(df[['A']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#evaluation metrics for supervised learning\n",
    "from sklearn.metrics import accuracy_score , precision_score,f1_score,roc_auc_score,recall_score\n",
    "y_true=df['B']\n",
    "y_pred=model.predict(df[['A']])\n",
    "acc=accuracy_score(y_true,y_pred)\n",
    "rec=recall_score(y_true,y_pred)\n",
    "prec=precision_score(y_true,y_pred)\n",
    "f1=f1_score(y_true,y_pred)\n",
    "roc=roc_auc_score(y_true,y_pred)\n",
    "print(acc)\n",
    "print(roc)\n",
    "print(f1)\n",
    "print(rec)\n",
    "print(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 1\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "# already existing dataframe\n",
    "model=LinearRegression()\n",
    "model.fit(df[['A']],df['B'])\n",
    "y_pred=model.predict(df[['A']])\n",
    "y_true=df['B']\n",
    "\n",
    "mae=mean_absolute_error(y_true,y_pred)\n",
    "mse=mean_squared_error(y_true,y_pred)\n",
    "rmse=np.sqrt(mse)\n",
    "r2=r2_score(y_true,y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devgo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#exercise 2\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "iris=load_iris()\n",
    "irisdf=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "irisdf['species']=iris.target\n",
    "model=LogisticRegression()\n",
    "model.fit(irisdf[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']], irisdf['species'])\n",
    "y_pred=model.predict(irisdf[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
    "y_true=irisdf['species']\n",
    "acc=accuracy_score(y_true,y_pred)\n",
    "prec=precision_score(y_true,y_pred,average='macro')#macro average as it is not binary classification\n",
    "recall=recall_score(y_true,y_pred,average='macro')\n",
    "f1=f1_score(y_true,y_pred,average='macro')\n",
    "\n",
    "#for roc auc we need to use label binarize \n",
    "lb=LabelBinarizer()\n",
    "y_true_b=lb.fit_transform(y_true)\n",
    "y_pred_b=lb.transform(y_pred)#after using fit transform once u can use transform\n",
    "roc=roc_auc_score(y_true_b,y_pred_b,multi_class='ovr')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unsupervised learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 2 0 2 1 1 1 2 2 2 1 2 1 2 1 1 0 0 1 2 1 1 0 0 0 0 0 2 1 0 1 0 0 0 1\n",
      " 0 1 2 0 2 1 1 2 1 2 1 0 2 0 1 0 2 0 2 0 2 0 1 2 1 2 0 0 2 1 2 0 1 2 2 0 1\n",
      " 1 0 2 1 1 1 2 2 2 2 0 2 1 1 0 1 1 2 2 1 1 2 1 1 1 2]\n",
      "[[0.32142108 0.86535795]\n",
      " [0.23955996 0.25138214]\n",
      " [0.80608355 0.53469821]]\n"
     ]
    }
   ],
   "source": [
    "#kmeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Create a random dataset\n",
    "X = np.random.rand(100, 2)\n",
    "\n",
    "kmeans=KMeans(n_clusters=3,random_state=0)\n",
    "kmeans.fit(X)\n",
    "labels=kmeans.labels_\n",
    "clustercenter=kmeans.cluster_centers_\n",
    "print(labels)\n",
    "print(clustercenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 0, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0, 2, 1, 1,\n",
       "       0, 1, 2, 1, 1, 2, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 2, 1, 2, 0, 0, 2,\n",
       "       1, 2, 0, 1, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 0, 2, 2, 0, 2, 1, 1,\n",
       "       0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hierarchical clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster=AgglomerativeClustering(n_clusters=3)\n",
    "#cluster=AgglomerativeClustering(n_clusters=3,linkage='ward')  here the clusters are more tightly grouped together\n",
    "cluster.fit(X)\n",
    "cluster.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  2,  6,  0,  7,  7,  6,  5,  1,  8,  9,\n",
       "        1,  4, 10,  6,  8, 11,  6, 12,  4, 10,  8,  4,  8,  2,  0,  6,  4,\n",
       "        4,  4,  6, 10,  6,  0,  4,  8,  1,  9,  8,  6,  5, 13, 13,  5,  4,\n",
       "        1,  8,  8, 12, 14,  4, 14, 10,  6,  0,  9,  8, 15, 12,  5,  6,  8,\n",
       "       15,  6,  5,  5, 15,  6,  6,  4,  7,  2,  6,  6,  0, 16,  7,  7,  4,\n",
       "        5,  6,  2,  4,  6,  1, 16,  8, 14,  2,  0,  1,  2,  6,  0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "db=DBSCAN(eps=0.1,min_samples=1)#if i put min samples =5 data doesnt have a core point so all defined as noise points\n",
    "db.fit(X)\n",
    "db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensionality reduction\n",
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "Xp=pca.fit_transform(X)\n",
    "Xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "#tsne (t distributed stochastic neighbors)\n",
    "from sklearn.manifold import TSNE\n",
    "tsne=TSNE(n_components=2)\n",
    "X_t=tsne.fit_transform(X)\n",
    "print(X_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics for unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4426221293875472\n"
     ]
    }
   ],
   "source": [
    "#silhouette score\n",
    "from sklearn.metrics import silhouette_score\n",
    "score=silhouette_score(X,labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7579996032402393\n"
     ]
    }
   ],
   "source": [
    "#davies bouldin index\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "dbi=davies_bouldin_score(X,labels)\n",
    "print(dbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55738749 0.44261251]\n"
     ]
    }
   ],
   "source": [
    "#explained variance ratio for PCA\n",
    "evr=pca.explained_variance_ratio_#simple syntax\n",
    "print(evr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning with neural networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single layer  perceptron\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, no_of_inputs, threshold=100, learning_rate=0.01):\n",
    "        self.threshold = threshold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_inputs + 1)  # Initialize weights to zeros\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]  # Include bias term\n",
    "        activation = 1 if summation > 0 else 0  # Simplified activation calculation\n",
    "        return activation\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.threshold):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                # Update weights including bias term\n",
    "                update = self.learning_rate * (label - prediction)\n",
    "                self.weights[1:] += update * inputs\n",
    "                self.weights[0] += update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4695 - loss: 0.7101  \n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4656 - loss: 0.6907 \n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5612 - loss: 0.6889 \n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.6879 \n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6444 - loss: 0.6744 \n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5975 - loss: 0.6759 \n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.6751 \n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 0.6745 \n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.6686 \n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7080 - loss: 0.6560 \n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6031 - loss: 0.6742 \n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6705 - loss: 0.6669 \n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6534 - loss: 0.6647 \n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 0.6802 \n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6270 - loss: 0.6715 \n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.6563 \n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5791 - loss: 0.6687 \n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7014 - loss: 0.6473\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.6566 \n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6438 - loss: 0.6619 \n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6603 - loss: 0.6561 \n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.6727 \n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 0.6554 \n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6455 - loss: 0.6566 \n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6393 - loss: 0.6607 \n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6574 - loss: 0.6476 \n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.6556 \n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6921 - loss: 0.6398 \n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6307 - loss: 0.6517 \n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.6595 \n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6299 - loss: 0.6501 \n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6365 - loss: 0.6424 \n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 0.6407 \n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6682 - loss: 0.6298 \n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6359 - loss: 0.6465 \n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6656 - loss: 0.6309 \n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6279 - loss: 0.6434 \n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6728 - loss: 0.6368 \n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6313 - loss: 0.6443 \n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5961 - loss: 0.6496 \n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.6319 \n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6233 - loss: 0.6377 \n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.6334 \n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - loss: 0.6241 \n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6692 - loss: 0.6374 \n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6452 - loss: 0.6509 \n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6613 - loss: 0.6339 \n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 0.6180 \n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7117 - loss: 0.6242 \n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6226 - loss: 0.6499 \n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.6153 \n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 0.6218 \n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6767 - loss: 0.6247 \n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 0.6327 \n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.6168 \n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.6170 \n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6423 - loss: 0.6389 \n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6985 - loss: 0.6165 \n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.6028 \n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7540 - loss: 0.5991 \n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.6135 \n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6293 - loss: 0.6198 \n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.6152 \n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6387 - loss: 0.6377 \n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.6175 \n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7136 - loss: 0.6124 \n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.6026 \n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.6212 \n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.6018 \n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.5942 \n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - loss: 0.6067 \n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7022 - loss: 0.5920 \n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.6109 \n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - loss: 0.6028 \n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6614 - loss: 0.6340 \n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.5891 \n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6471 - loss: 0.6334 \n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6911 - loss: 0.6195 \n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6767 - loss: 0.6179 \n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6276 - loss: 0.6350 \n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7579 - loss: 0.5724 \n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7026 - loss: 0.5949 \n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.5990 \n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7311 - loss: 0.5840 \n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6456 - loss: 0.6122 \n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 0.6097 \n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7674 - loss: 0.5639 \n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.5994 \n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.5814 \n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7167 - loss: 0.5779 \n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 0.6070 \n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.5859 \n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7244 - loss: 0.5940 \n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.5968 \n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6699 - loss: 0.5930 \n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.5809 \n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6934 - loss: 0.5915 \n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.5723 \n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.6094 \n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.5678 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae517f950>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "import numpy as np\n",
    "X=np.random.rand(100,8)\n",
    "y=np.random.randint(2,size=(100,1))\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(8,)))#explicit input layer in new version\n",
    "model.add(Dense (32,activation=\"relu\"))#hidden layer\n",
    "model.add(Dense(1,activation='sigmoid'))#output layer\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])#compile the model\n",
    "#adam optimizer used is a variant of gradient descent \n",
    "model.fit(X,y,epochs=100,batch_size=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5282 - loss: 0.7120  \n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5434 - loss: 0.7072 \n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5267 - loss: 0.7092 \n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.7074 \n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4823 - loss: 0.7131 \n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.7130 \n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5128 - loss: 0.7045 \n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5374 - loss: 0.7024 \n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4822 - loss: 0.7066 \n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5547 - loss: 0.6974 \n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4999 - loss: 0.7038 \n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5543 - loss: 0.6960 \n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: 0.7010 \n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5592 - loss: 0.6938 \n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.5115 - loss: 0.6991\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4530 - loss: 0.7046 \n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4895 - loss: 0.6997 \n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5135 - loss: 0.6975 \n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5304 - loss: 0.6954 \n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5096 - loss: 0.6974 \n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5265 - loss: 0.6943 \n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4954 - loss: 0.6992 \n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4694 - loss: 0.7003 \n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5653 - loss: 0.6894 \n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4867 - loss: 0.6976 \n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4897 - loss: 0.6976 \n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4701 - loss: 0.6995 \n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6916 \n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5687 - loss: 0.6869 \n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5440 - loss: 0.6915 \n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5469 - loss: 0.6879 \n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5201 - loss: 0.6925 \n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4980 - loss: 0.6951 \n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4895 - loss: 0.6948 \n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 0.6877 \n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4895 - loss: 0.6947 \n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5388 - loss: 0.6879 \n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4684 - loss: 0.6978 \n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5106 - loss: 0.6933 \n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4686 - loss: 0.6966 \n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4950 - loss: 0.6946 \n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 0.6765 \n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4894 - loss: 0.6945 \n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4916 - loss: 0.6918 \n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5117 - loss: 0.6930 \n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 0.6905 \n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4998 - loss: 0.6938 \n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5681 - loss: 0.6814 \n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4966 - loss: 0.6930 \n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5072 - loss: 0.6908 \n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5182 - loss: 0.6887 \n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4804 - loss: 0.6956 \n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5703 - loss: 0.6829 \n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5109 - loss: 0.6914 \n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4545 - loss: 0.6976 \n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5139 - loss: 0.6897 \n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5257 - loss: 0.6865 \n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5510 - loss: 0.6852 \n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4946 - loss: 0.6871 \n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5073 - loss: 0.6914 \n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4344 - loss: 0.7003 \n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5383 - loss: 0.6848 \n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4855 - loss: 0.6924 \n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5679 - loss: 0.6828 \n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4801 - loss: 0.6917 \n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5036 - loss: 0.6892 \n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5397 - loss: 0.6832 \n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4439 - loss: 0.6971 \n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5479 - loss: 0.6846 \n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4928 - loss: 0.6878 \n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 0.6872 \n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4781 - loss: 0.6894 \n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5175 - loss: 0.6835 \n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4306 - loss: 0.6997 \n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 0.6873 \n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5922 - loss: 0.6769 \n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5145 - loss: 0.6833 \n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5443 - loss: 0.6851 \n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5115 - loss: 0.6867 \n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4519 - loss: 0.6907 \n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5473 - loss: 0.6791 \n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5417 - loss: 0.6847 \n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4889 - loss: 0.6876 \n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4969 - loss: 0.6857 \n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5533 - loss: 0.6770 \n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5028 - loss: 0.6854 \n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5734 - loss: 0.6753 \n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5344 - loss: 0.6751 \n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4613 - loss: 0.6850 \n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5013 - loss: 0.6814 \n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5153 - loss: 0.6864 \n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5427 - loss: 0.6787 \n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5407 - loss: 0.6780 \n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5314 - loss: 0.6843 \n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4918 - loss: 0.6862 \n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 0.6809 \n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 0.6823 \n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5405 - loss: 0.6787 \n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5600 - loss: 0.6755 \n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4721 - loss: 0.6889 \n",
      "loss 0.6813787817955017\n",
      "accuracy 0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Input(shape=(8,)))\n",
    "model1.add(Dense(32,activation='sigmoid')) #sigmoid activation hidden layer\n",
    "model1.add(Dense(32,activation='relu'))#relu\n",
    "model1.add(Dense(32,activation='tanh'))#hyperbolic tangent\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=100,batch_size=10)\n",
    "\n",
    "#evaluating the model\n",
    "score=model.evaluate(X,y,verbose=0)\n",
    "print('loss',score[0])\n",
    "print('accuracy',score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3759 - loss: 0.7192     \n",
      "Epoch 2/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5388 - loss: 0.6865   \n",
      "Epoch 3/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6049 - loss: 0.6809   \n",
      "Epoch 4/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6620 - loss: 0.6545  \n",
      "Epoch 5/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.6169 - loss: 0.6528\n",
      "Epoch 6/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5823 - loss: 0.6823   \n",
      "Epoch 7/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.6167 - loss: 0.6656\n",
      "Epoch 8/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6357 - loss: 0.6684   \n",
      "Epoch 9/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4931 - loss: 0.6918  \n",
      "Epoch 10/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6463 - loss: 0.6380  \n",
      "Epoch 11/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6683 - loss: 0.6476  \n",
      "Epoch 12/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6650 - loss: 0.6428  \n",
      "Epoch 13/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.5857 - loss: 0.6437\n",
      "Epoch 14/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.7255 - loss: 0.6182\n",
      "Epoch 15/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.6739 - loss: 0.6349 \n",
      "Epoch 16/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.5941 - loss: 0.6432 \n",
      "Epoch 17/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.5956 - loss: 0.6349\n",
      "Epoch 18/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6356 - loss: 0.6367\n",
      "Epoch 19/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6284 - loss: 0.6928\n",
      "Epoch 20/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6748 - loss: 0.5617   \n",
      "Epoch 21/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.6895 - loss: 0.5683\n",
      "Epoch 22/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6764 - loss: 0.5830\n",
      "Epoch 23/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6890 - loss: 0.5858\n",
      "Epoch 24/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7555 - loss: 0.5683  \n",
      "Epoch 25/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.6765 - loss: 0.5765 \n",
      "Epoch 26/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.6711 - loss: 0.5823\n",
      "Epoch 27/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6406 - loss: 0.5886\n",
      "Epoch 28/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6750 - loss: 0.5971   \n",
      "Epoch 29/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7236 - loss: 0.5390  \n",
      "Epoch 30/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.6924 - loss: 0.5473 \n",
      "Epoch 31/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7153 - loss: 0.5344\n",
      "Epoch 32/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7820 - loss: 0.4978  \n",
      "Epoch 33/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7911 - loss: 0.4663\n",
      "Epoch 34/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.7497 - loss: 0.5379\n",
      "Epoch 35/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.7296 - loss: 0.5264\n",
      "Epoch 36/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7397 - loss: 0.4590\n",
      "Epoch 37/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7500 - loss: 0.5203\n",
      "Epoch 38/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.6898 - loss: 0.4944\n",
      "Epoch 39/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7542 - loss: 0.5339\n",
      "Epoch 40/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.7362 - loss: 0.5100\n",
      "Epoch 41/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7670 - loss: 0.4750\n",
      "Epoch 42/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.7692 - loss: 0.4481\n",
      "Epoch 43/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8168 - loss: 0.4652\n",
      "Epoch 44/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.7903 - loss: 0.5328\n",
      "Epoch 45/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7583 - loss: 0.4904   \n",
      "Epoch 46/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8511 - loss: 0.4776  \n",
      "Epoch 47/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.4392  \n",
      "Epoch 48/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.8673 - loss: 0.3522\n",
      "Epoch 49/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 0.4535  \n",
      "Epoch 50/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.8269 - loss: 0.3925\n",
      "Epoch 51/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7814 - loss: 0.4387\n",
      "Epoch 52/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8263 - loss: 0.4405\n",
      "Epoch 53/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.8677 - loss: 0.4117\n",
      "Epoch 54/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8076 - loss: 0.4065\n",
      "Epoch 55/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.8734 - loss: 0.3691\n",
      "Epoch 56/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7489 - loss: 0.4853\n",
      "Epoch 57/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 0.4108  \n",
      "Epoch 58/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.4011  \n",
      "Epoch 59/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7733 - loss: 0.4126\n",
      "Epoch 60/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8172 - loss: 0.3947\n",
      "Epoch 61/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.7181 - loss: 0.5543 \n",
      "Epoch 62/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9087 - loss: 0.3148\n",
      "Epoch 63/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9013 - loss: 0.3475\n",
      "Epoch 64/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.8945 - loss: 0.2510\n",
      "Epoch 65/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.8520 - loss: 0.3450\n",
      "Epoch 66/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.8678 - loss: 0.3674\n",
      "Epoch 67/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8180 - loss: 0.3695   \n",
      "Epoch 68/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8706 - loss: 0.3643\n",
      "Epoch 69/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8956 - loss: 0.3199\n",
      "Epoch 70/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.8399 - loss: 0.3031\n",
      "Epoch 71/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.8093 - loss: 0.4050\n",
      "Epoch 72/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.8067 - loss: 0.3832\n",
      "Epoch 73/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8744 - loss: 0.3664\n",
      "Epoch 74/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9153 - loss: 0.2680\n",
      "Epoch 75/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9273 - loss: 0.2330\n",
      "Epoch 76/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.8887 - loss: 0.3008\n",
      "Epoch 77/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.2525   \n",
      "Epoch 78/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8517 - loss: 0.3453\n",
      "Epoch 79/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2781  \n",
      "Epoch 80/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9567 - loss: 0.2349\n",
      "Epoch 81/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8686 - loss: 0.3049 \n",
      "Epoch 82/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.9067 - loss: 0.2585\n",
      "Epoch 83/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8925 - loss: 0.2921\n",
      "Epoch 84/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.8894 - loss: 0.3103\n",
      "Epoch 85/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.8285 - loss: 0.3237\n",
      "Epoch 86/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9607 - loss: 0.2011\n",
      "Epoch 87/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.2297  \n",
      "Epoch 88/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9017 - loss: 0.2475 \n",
      "Epoch 89/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9254 - loss: 0.2246\n",
      "Epoch 90/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9039 - loss: 0.2922\n",
      "Epoch 91/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.8798 - loss: 0.2399\n",
      "Epoch 92/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9366 - loss: 0.1763\n",
      "Epoch 93/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.8997 - loss: 0.2008\n",
      "Epoch 94/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9734 - loss: 0.1413  \n",
      "Epoch 95/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.3633   \n",
      "Epoch 96/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1618  \n",
      "Epoch 97/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9727 - loss: 0.1688\n",
      "Epoch 98/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9566 - loss: 0.1373\n",
      "Epoch 99/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9455 - loss: 0.1757\n",
      "Epoch 100/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9530 - loss: 0.1603\n",
      "Epoch 101/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9691 - loss: 0.1476\n",
      "Epoch 102/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1821  \n",
      "Epoch 103/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9362 - loss: 0.1835  \n",
      "Epoch 104/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.9822 - loss: 0.1081\n",
      "Epoch 105/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.1196  \n",
      "Epoch 106/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9580 - loss: 0.1459\n",
      "Epoch 107/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.9843 - loss: 0.1074\n",
      "Epoch 108/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.9829 - loss: 0.0719\n",
      "Epoch 109/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9938 - loss: 0.0621\n",
      "Epoch 110/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9633 - loss: 0.1275\n",
      "Epoch 111/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9712 - loss: 0.1070  \n",
      "Epoch 112/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9567 - loss: 0.0978\n",
      "Epoch 113/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9573 - loss: 0.0958 \n",
      "Epoch 114/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9765 - loss: 0.1292\n",
      "Epoch 115/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.1407  \n",
      "Epoch 116/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9805 - loss: 0.0930  \n",
      "Epoch 117/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9940 - loss: 0.0737  \n",
      "Epoch 118/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9633 - loss: 0.0896\n",
      "Epoch 119/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 0.0847\n",
      "Epoch 120/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9942 - loss: 0.0755\n",
      "Epoch 121/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.1024  \n",
      "Epoch 122/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.1111  \n",
      "Epoch 123/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0756  \n",
      "Epoch 124/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0641   \n",
      "Epoch 125/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9910 - loss: 0.0556\n",
      "Epoch 126/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.9855 - loss: 0.0646\n",
      "Epoch 127/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 1.0000 - loss: 0.0433\n",
      "Epoch 128/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9911 - loss: 0.0448\n",
      "Epoch 129/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 1.0000 - loss: 0.0473\n",
      "Epoch 130/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0448\n",
      "Epoch 131/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0339\n",
      "Epoch 132/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9961 - loss: 0.0554\n",
      "Epoch 133/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9994 - loss: 0.0530\n",
      "Epoch 134/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9639 - loss: 0.1143 \n",
      "Epoch 135/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9769 - loss: 0.0895  \n",
      "Epoch 136/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9484 - loss: 0.1677\n",
      "Epoch 137/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0763\n",
      "Epoch 138/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.9914 - loss: 0.0640\n",
      "Epoch 139/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0382  \n",
      "Epoch 140/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 0.0290\n",
      "Epoch 141/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0379\n",
      "Epoch 142/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0282\n",
      "Epoch 143/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0306\n",
      "Epoch 144/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9968 - loss: 0.0350\n",
      "Epoch 145/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 1.0000 - loss: 0.0304\n",
      "Epoch 146/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 0.0346\n",
      "Epoch 147/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 0.0216\n",
      "Epoch 148/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 0.0220\n",
      "Epoch 149/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0184   \n",
      "Epoch 150/150\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 0.0285 \n",
      "Epoch 1/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9900 - loss: 0.0492\n",
      "Epoch 2/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9900 - loss: 0.0481\n",
      "Epoch 3/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9900 - loss: 0.0467\n",
      "Epoch 4/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9900 - loss: 0.0453\n",
      "Epoch 5/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9900 - loss: 0.0438\n",
      "Epoch 6/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9900 - loss: 0.0422\n",
      "Epoch 7/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9900 - loss: 0.0406\n",
      "Epoch 8/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9900 - loss: 0.0392\n",
      "Epoch 9/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9900 - loss: 0.0378\n",
      "Epoch 10/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0366\n",
      "Epoch 11/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0355\n",
      "Epoch 12/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0345\n",
      "Epoch 13/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0335\n",
      "Epoch 14/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0327\n",
      "Epoch 15/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0320\n",
      "Epoch 16/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0313\n",
      "Epoch 17/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0307\n",
      "Epoch 18/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0301\n",
      "Epoch 19/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0296\n",
      "Epoch 20/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0291\n",
      "Epoch 21/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0285\n",
      "Epoch 22/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0280\n",
      "Epoch 23/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0275\n",
      "Epoch 24/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0270\n",
      "Epoch 25/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0265\n",
      "Epoch 26/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0259\n",
      "Epoch 27/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0254\n",
      "Epoch 28/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0249\n",
      "Epoch 29/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0244\n",
      "Epoch 30/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0240\n",
      "Epoch 31/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0235\n",
      "Epoch 32/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0231\n",
      "Epoch 33/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0227\n",
      "Epoch 34/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0223\n",
      "Epoch 35/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0220\n",
      "Epoch 36/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0217\n",
      "Epoch 37/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0214\n",
      "Epoch 38/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0211\n",
      "Epoch 39/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0208\n",
      "Epoch 40/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0206\n",
      "Epoch 41/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0204\n",
      "Epoch 42/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0202\n",
      "Epoch 43/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0200\n",
      "Epoch 44/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0198\n",
      "Epoch 45/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0197\n",
      "Epoch 46/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0196\n",
      "Epoch 47/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0194\n",
      "Epoch 48/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0193\n",
      "Epoch 49/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0192\n",
      "Epoch 50/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0191\n",
      "Epoch 51/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0190\n",
      "Epoch 52/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0189\n",
      "Epoch 53/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0188\n",
      "Epoch 54/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0188\n",
      "Epoch 55/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0187\n",
      "Epoch 56/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0186\n",
      "Epoch 57/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0186\n",
      "Epoch 58/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0185\n",
      "Epoch 59/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0185\n",
      "Epoch 60/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 61/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0184\n",
      "Epoch 62/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0183\n",
      "Epoch 63/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0183\n",
      "Epoch 64/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0183\n",
      "Epoch 65/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 66/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 67/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 68/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 69/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0182\n",
      "Epoch 70/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 71/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 72/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 73/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 74/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0181\n",
      "Epoch 75/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 76/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 77/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 78/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 79/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 80/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 81/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 82/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 83/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 84/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0179\n",
      "Epoch 85/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 86/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 87/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 88/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 89/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 90/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0178\n",
      "Epoch 91/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 92/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 93/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 94/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 95/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 96/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 97/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0177\n",
      "Epoch 98/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 99/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 100/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 101/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 102/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 103/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0176\n",
      "Epoch 104/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 105/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 106/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 107/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 108/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 109/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 110/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 111/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0175\n",
      "Epoch 112/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 113/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 114/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 115/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 116/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 117/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 118/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 119/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 120/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 121/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 122/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 123/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 124/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 125/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 126/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 127/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 128/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 129/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 130/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 131/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 132/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 133/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 134/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 135/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 136/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0172\n",
      "Epoch 137/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 138/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 139/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 140/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 141/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 142/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 143/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 144/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 145/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 146/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0171\n",
      "Epoch 147/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 148/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 149/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 150/150\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0170\n",
      "Epoch 1/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0170 \n",
      "Epoch 2/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 3/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0164 \n",
      "Epoch 4/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0165 \n",
      "Epoch 5/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0179 \n",
      "Epoch 6/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 7/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 8/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0159 \n",
      "Epoch 9/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0192 \n",
      "Epoch 10/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0179 \n",
      "Epoch 11/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0170 \n",
      "Epoch 12/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 13/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 14/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 15/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0163 \n",
      "Epoch 16/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0164 \n",
      "Epoch 17/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 18/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0176 \n",
      "Epoch 19/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0163 \n",
      "Epoch 20/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 21/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0159 \n",
      "Epoch 22/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0171 \n",
      "Epoch 23/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 24/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 25/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 26/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0152 \n",
      "Epoch 27/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 28/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0159 \n",
      "Epoch 29/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0150 \n",
      "Epoch 30/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0165 \n",
      "Epoch 31/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0164 \n",
      "Epoch 32/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0162 \n",
      "Epoch 33/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 34/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0167 \n",
      "Epoch 35/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 36/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0175 \n",
      "Epoch 37/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 38/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0170 \n",
      "Epoch 39/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 40/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0170 \n",
      "Epoch 41/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0175 \n",
      "Epoch 42/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0165 \n",
      "Epoch 43/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0171 \n",
      "Epoch 44/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0172 \n",
      "Epoch 45/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 46/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 47/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0170 \n",
      "Epoch 48/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0150 \n",
      "Epoch 49/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0171 \n",
      "Epoch 50/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0161 \n",
      "Epoch 51/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 52/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0161 \n",
      "Epoch 53/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0171 \n",
      "Epoch 54/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 55/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 56/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0161 \n",
      "Epoch 57/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0167 \n",
      "Epoch 58/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0162 \n",
      "Epoch 59/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0152 \n",
      "Epoch 60/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0163 \n",
      "Epoch 61/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0164 \n",
      "Epoch 62/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 63/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0174 \n",
      "Epoch 64/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 65/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0147 \n",
      "Epoch 66/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 67/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 68/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 69/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 70/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0144 \n",
      "Epoch 71/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0167 \n",
      "Epoch 72/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 73/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 74/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0163 \n",
      "Epoch 75/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0153 \n",
      "Epoch 76/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 77/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0159 \n",
      "Epoch 78/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0141 \n",
      "Epoch 79/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 80/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0170 \n",
      "Epoch 81/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0150 \n",
      "Epoch 82/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 83/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0163 \n",
      "Epoch 84/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 85/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 86/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 87/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 88/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 89/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 90/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0169 \n",
      "Epoch 91/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 92/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0165 \n",
      "Epoch 93/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0150 \n",
      "Epoch 94/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0161 \n",
      "Epoch 95/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0165 \n",
      "Epoch 96/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0163 \n",
      "Epoch 97/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 98/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0134 \n",
      "Epoch 99/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 100/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 101/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0169 \n",
      "Epoch 102/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0147 \n",
      "Epoch 103/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 104/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0162 \n",
      "Epoch 105/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 106/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0177 \n",
      "Epoch 107/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0141 \n",
      "Epoch 108/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0147 \n",
      "Epoch 109/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 110/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0138 \n",
      "Epoch 111/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 112/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 113/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0152 \n",
      "Epoch 114/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0143 \n",
      "Epoch 115/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 116/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0140 \n",
      "Epoch 117/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 118/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0154 \n",
      "Epoch 119/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0144 \n",
      "Epoch 120/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0152 \n",
      "Epoch 121/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 122/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0139 \n",
      "Epoch 123/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0149 \n",
      "Epoch 124/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0157 \n",
      "Epoch 125/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0168 \n",
      "Epoch 126/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0153 \n",
      "Epoch 127/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0173 \n",
      "Epoch 128/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0142\n",
      "Epoch 129/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0144 \n",
      "Epoch 130/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 131/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0145 \n",
      "Epoch 132/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0150 \n",
      "Epoch 133/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0141 \n",
      "Epoch 134/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 135/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0137 \n",
      "Epoch 136/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 137/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0160 \n",
      "Epoch 138/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0142 \n",
      "Epoch 139/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0140 \n",
      "Epoch 140/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0138 \n",
      "Epoch 141/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0148 \n",
      "Epoch 142/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0130 \n",
      "Epoch 143/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0156 \n",
      "Epoch 144/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0131 \n",
      "Epoch 145/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0146 \n",
      "Epoch 146/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0150 \n",
      "Epoch 147/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0155 \n",
      "Epoch 148/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0151 \n",
      "Epoch 149/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0137 \n",
      "Epoch 150/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0145 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae8c5c530>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient descent types\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(8,)))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "sgd=SGD(learning_rate=0.01,momentum=0.9,nesterov=True)#setting the learning rate\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=150,batch_size=1) #SGD\n",
    "model.fit(X,y,epochs=150,batch_size=len(X))#BGD\n",
    "model.fit(X,y,epochs=150,batch_size=32)# mini BGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5045 - loss: 0.6990  \n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4361 - loss: 0.7002 \n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4581 - loss: 0.6949 \n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4435 - loss: 0.6973 \n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4425 - loss: 0.6950 \n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4423 - loss: 0.6944 \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4932 - loss: 0.6892 \n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4955 - loss: 0.6881\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4850 - loss: 0.6886 \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4765 - loss: 0.6901 \n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4722 - loss: 0.6917\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4910 - loss: 0.6856 \n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4722 - loss: 0.6873\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4847 - loss: 0.6857 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5464 - loss: 0.6797 \n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5625 - loss: 0.6842 \n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5943 - loss: 0.6850 \n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5396 - loss: 0.6856 \n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5511 - loss: 0.6795 \n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5838 - loss: 0.6819 \n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5570 - loss: 0.6810 \n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5778 - loss: 0.6797 \n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5829 - loss: 0.6774 \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5987 - loss: 0.6738 \n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5851 - loss: 0.6748 \n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5945 - loss: 0.6709 \n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5633 - loss: 0.6776 \n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 0.6742 \n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6006 - loss: 0.6700 \n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6004 - loss: 0.6767 \n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5652 - loss: 0.6742 \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5382 - loss: 0.6771 \n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 0.6750 \n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6110 - loss: 0.6624 \n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6056 - loss: 0.6676 \n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5775 - loss: 0.6720 \n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6087 - loss: 0.6640 \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6378 - loss: 0.6554 \n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6395 - loss: 0.6606 \n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6303 - loss: 0.6650 \n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6030 - loss: 0.6674 \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6510 - loss: 0.6607 \n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6050 - loss: 0.6699 \n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6744 - loss: 0.6603 \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6775 - loss: 0.6626 \n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6202 - loss: 0.6699 \n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6215 - loss: 0.6672 \n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6579 - loss: 0.6598 \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6310 - loss: 0.6640 \n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6685 - loss: 0.6529 \n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6018 - loss: 0.6629 \n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6300 - loss: 0.6577 \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6322 - loss: 0.6551 \n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6402 - loss: 0.6592 \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6640 - loss: 0.6583 \n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6817 - loss: 0.6538 \n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6119 - loss: 0.6636 \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6381 - loss: 0.6585 \n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6508 - loss: 0.6574 \n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6465 - loss: 0.6574 \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6423 - loss: 0.6493 \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6777 - loss: 0.6479 \n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6921 - loss: 0.6472 \n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6586 - loss: 0.6615 \n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6527 - loss: 0.6521 \n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6829 - loss: 0.6456 \n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6650 - loss: 0.6506 \n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6317 - loss: 0.6608 \n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6753 - loss: 0.6478 \n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6713 - loss: 0.6474 \n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6795 - loss: 0.6523 \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6880 - loss: 0.6477 \n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6732 - loss: 0.6512 \n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6399 - loss: 0.6557 \n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7281 - loss: 0.6444 \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6916 - loss: 0.6486 \n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6512 - loss: 0.6523 \n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7032 - loss: 0.6462 \n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6751 - loss: 0.6500 \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6699 - loss: 0.6513 \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6887 - loss: 0.6458 \n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6743 - loss: 0.6481 \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6647 - loss: 0.6452 \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6930 - loss: 0.6378 \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6722 - loss: 0.6467 \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6734 - loss: 0.6430 \n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6359 - loss: 0.6529 \n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6621 - loss: 0.6386 \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6704 - loss: 0.6378 \n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6735 - loss: 0.6400 \n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6223 - loss: 0.6492 \n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6690 - loss: 0.6393 \n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6824 - loss: 0.6471 \n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6824 - loss: 0.6406 \n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6678 - loss: 0.6459 \n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6857 - loss: 0.6330 \n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6536 - loss: 0.6433 \n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6701 - loss: 0.6384 \n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6453 - loss: 0.6368 \n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 0.6444 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae9d6ef30>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the learning rate\n",
    "from tensorflow.keras.optimizers import SGD,Adam,Adagrad,RMSprop\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(8,)))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "sgd=SGD(learning_rate=0.01,momentum=0.9,nesterov=True)\n",
    "adam=Adam(learning_rate=0.01)\n",
    "ada=Adagrad(learning_rate=0.01)\n",
    "rms=RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) #adam gives the best performance\n",
    "#model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='ada',metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer='rms',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=100,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5757 - loss: 0.8252  \n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4679 - loss: 0.8366 \n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 0.8105 \n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5615 - loss: 0.8037 \n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4957 - loss: 0.8229 \n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4798 - loss: 0.8127 \n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4817 - loss: 0.8099 \n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5526 - loss: 0.7880 \n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5758 - loss: 0.7769 \n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5383 - loss: 0.7834 \n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5395 - loss: 0.7829 \n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5239 - loss: 0.7736 \n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 0.7822 \n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5636 - loss: 0.7657 \n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5034 - loss: 0.7698 \n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5854 - loss: 0.7532 \n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5191 - loss: 0.7661 \n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5127 - loss: 0.7629 \n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6080 - loss: 0.7475 \n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 0.7470 \n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6354 - loss: 0.7372 \n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6468 - loss: 0.7343 \n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6318 - loss: 0.7294 \n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6965 - loss: 0.7194 \n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5540 - loss: 0.7424 \n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6107 - loss: 0.7337 \n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5749 - loss: 0.7325 \n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6500 - loss: 0.7327 \n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5536 - loss: 0.7345 \n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 0.7269 \n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.7297 \n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6115 - loss: 0.7117 \n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 0.7203 \n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.7260 \n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 0.7119 \n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 0.7034 \n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6303 - loss: 0.7141 \n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6526 - loss: 0.7057 \n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6796 - loss: 0.6942 \n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6451 - loss: 0.7045 \n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6375 - loss: 0.7073 \n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6392 - loss: 0.6943 \n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6426 - loss: 0.7038 \n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6536 - loss: 0.6964 \n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6433 - loss: 0.6972 \n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 0.6958 \n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6019 - loss: 0.7016 \n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 0.6890 \n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6356 - loss: 0.6917 \n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6435 - loss: 0.6945 \n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6729 - loss: 0.6953 \n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5716 - loss: 0.7060 \n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.7040 \n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.6737 \n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.6956 \n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6524 - loss: 0.6962 \n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6500 - loss: 0.6949 \n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5637 - loss: 0.6958 \n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6647 - loss: 0.6800 \n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6489 - loss: 0.6876 \n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6158 - loss: 0.6895 \n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 0.6807 \n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6620 \n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 0.6888 \n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.6780 \n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.6736 \n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6621 - loss: 0.6761 \n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7012 - loss: 0.6703 \n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5786 - loss: 0.6746 \n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5837 - loss: 0.6814 \n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 0.6674 \n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6691 - loss: 0.6710 \n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6661 - loss: 0.6572 \n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6409 - loss: 0.6689 \n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6767 - loss: 0.6606 \n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6401 - loss: 0.6662 \n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.6795 \n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6130 - loss: 0.6841 \n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6334 - loss: 0.6692 \n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.6797 \n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6450 - loss: 0.6628 \n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.6515 \n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6667 - loss: 0.6666 \n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6767 - loss: 0.6635 \n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5873 - loss: 0.6786 \n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6385 - loss: 0.6636 \n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6016 - loss: 0.6754 \n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6620 - loss: 0.6503 \n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6441 - loss: 0.6627 \n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5465 - loss: 0.6802 \n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5750 - loss: 0.6776 \n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6173 - loss: 0.6661 \n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6686 - loss: 0.6592 \n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6564 - loss: 0.6558 \n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: 0.6604 \n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6613 - loss: 0.6515 \n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6467 - loss: 0.6558 \n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5547 - loss: 0.6843 \n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6649 - loss: 0.6665 \n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 0.6381 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17aeae606b0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyperparameter tuning\n",
    "from tensorflow.keras.regularizers import l2\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(8,)))\n",
    "model.add(Dense(32,activation='relu',kernel_regularizer=l2(0.01)))#l2 with weight decay of 0.01(penalizes large weights)\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6720 - loss: 0.6579 - val_accuracy: 0.7500 - val_loss: 0.5953\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6170 - loss: 0.6736 - val_accuracy: 0.7000 - val_loss: 0.6003\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5889 - loss: 0.6727 - val_accuracy: 0.8000 - val_loss: 0.6106\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7222 - loss: 0.6496 - val_accuracy: 0.7000 - val_loss: 0.6085\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5596 - loss: 0.6719 - val_accuracy: 0.7000 - val_loss: 0.6101\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6167 - loss: 0.6627 - val_accuracy: 0.7000 - val_loss: 0.6114\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6062 - loss: 0.6698 - val_accuracy: 0.7000 - val_loss: 0.6151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17aeae614f0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es=EarlyStopping(patience=6)#handles the stoppage, patience=6 means if it does not improve on validation set till 6 epochs it will stop\n",
    "model.fit(X,y,epochs=100,batch_size=10,validation_split=0.2,callbacks=[es])#20 percent of data is used as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5682 - loss: 0.7964 - val_accuracy: 0.4000 - val_loss: 0.8501\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4673 - loss: 0.8593 - val_accuracy: 0.4000 - val_loss: 0.8339\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5487 - loss: 0.8022 - val_accuracy: 0.4500 - val_loss: 0.8196\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5094 - loss: 0.8448 - val_accuracy: 0.4000 - val_loss: 0.8106\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3369 - loss: 0.8974 - val_accuracy: 0.5000 - val_loss: 0.7990\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4334 - loss: 0.8302 - val_accuracy: 0.5500 - val_loss: 0.7942\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4405 - loss: 0.8280 - val_accuracy: 0.6000 - val_loss: 0.7907\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5467 - loss: 0.8293 - val_accuracy: 0.5500 - val_loss: 0.7905\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5178 - loss: 0.8052 - val_accuracy: 0.6000 - val_loss: 0.7867\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4989 - loss: 0.8092 - val_accuracy: 0.6000 - val_loss: 0.7837\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4149 - loss: 0.8422 - val_accuracy: 0.6000 - val_loss: 0.7785\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5608 - loss: 0.8122 - val_accuracy: 0.6000 - val_loss: 0.7768\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4298 - loss: 0.8085 - val_accuracy: 0.6000 - val_loss: 0.7772\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5278 - loss: 0.7943 - val_accuracy: 0.6000 - val_loss: 0.7763\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5423 - loss: 0.7645 - val_accuracy: 0.6000 - val_loss: 0.7772\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4434 - loss: 0.7968 - val_accuracy: 0.6000 - val_loss: 0.7759\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3723 - loss: 0.8058 - val_accuracy: 0.5500 - val_loss: 0.7724\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5844 - loss: 0.7795 - val_accuracy: 0.5500 - val_loss: 0.7710\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5294 - loss: 0.7815 - val_accuracy: 0.5500 - val_loss: 0.7712\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4625 - loss: 0.8093 - val_accuracy: 0.5500 - val_loss: 0.7706\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6263 - loss: 0.7324 - val_accuracy: 0.5500 - val_loss: 0.7723\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5463 - loss: 0.7558 - val_accuracy: 0.4000 - val_loss: 0.7720\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5548 - loss: 0.7586 - val_accuracy: 0.4000 - val_loss: 0.7740\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5484 - loss: 0.7607 - val_accuracy: 0.5500 - val_loss: 0.7681\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4658 - loss: 0.7745 - val_accuracy: 0.5500 - val_loss: 0.7660\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4420 - loss: 0.7723 - val_accuracy: 0.6000 - val_loss: 0.7633\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5003 - loss: 0.7715 - val_accuracy: 0.6000 - val_loss: 0.7582\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4434 - loss: 0.7706 - val_accuracy: 0.6000 - val_loss: 0.7598\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5337 - loss: 0.7696 - val_accuracy: 0.6000 - val_loss: 0.7595\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6622 - loss: 0.7126 - val_accuracy: 0.6000 - val_loss: 0.7576\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6193 - loss: 0.7557 - val_accuracy: 0.6000 - val_loss: 0.7551\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7001 - loss: 0.7132 - val_accuracy: 0.6000 - val_loss: 0.7526\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5745 - loss: 0.7641 - val_accuracy: 0.5500 - val_loss: 0.7500\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5876 - loss: 0.7446 - val_accuracy: 0.5500 - val_loss: 0.7481\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6184 - loss: 0.7180 - val_accuracy: 0.5500 - val_loss: 0.7471\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5702 - loss: 0.7396 - val_accuracy: 0.5500 - val_loss: 0.7451\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5948 - loss: 0.7459 - val_accuracy: 0.5500 - val_loss: 0.7457\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5588 - loss: 0.7548 - val_accuracy: 0.5500 - val_loss: 0.7415\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5103 - loss: 0.7635 - val_accuracy: 0.5500 - val_loss: 0.7408\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4507 - loss: 0.7742 - val_accuracy: 0.5500 - val_loss: 0.7393\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5222 - loss: 0.7297 - val_accuracy: 0.5000 - val_loss: 0.7390\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4983 - loss: 0.7422 - val_accuracy: 0.5500 - val_loss: 0.7407\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5048 - loss: 0.7502 - val_accuracy: 0.5500 - val_loss: 0.7404\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5847 - loss: 0.7374 - val_accuracy: 0.5500 - val_loss: 0.7429\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6347 - loss: 0.7009 - val_accuracy: 0.5500 - val_loss: 0.7432\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6268 - loss: 0.7215 - val_accuracy: 0.5500 - val_loss: 0.7433\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5354 - loss: 0.7063 - val_accuracy: 0.5500 - val_loss: 0.7445\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5327 - loss: 0.7611 - val_accuracy: 0.5000 - val_loss: 0.7438\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5505 - loss: 0.7345 - val_accuracy: 0.5500 - val_loss: 0.7399\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5409 - loss: 0.7429 - val_accuracy: 0.5000 - val_loss: 0.7386\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4957 - loss: 0.7339 - val_accuracy: 0.5000 - val_loss: 0.7364\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5733 - loss: 0.7315 - val_accuracy: 0.5000 - val_loss: 0.7346\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.7236 - val_accuracy: 0.5000 - val_loss: 0.7301\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6053 - loss: 0.7158 - val_accuracy: 0.5000 - val_loss: 0.7286\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5924 - loss: 0.6996 - val_accuracy: 0.5000 - val_loss: 0.7273\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5743 - loss: 0.7241 - val_accuracy: 0.5500 - val_loss: 0.7241\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5075 - loss: 0.7260 - val_accuracy: 0.5500 - val_loss: 0.7231\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4992 - loss: 0.7344 - val_accuracy: 0.5500 - val_loss: 0.7250\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4609 - loss: 0.7225 - val_accuracy: 0.4500 - val_loss: 0.7258\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5144 - loss: 0.7471 - val_accuracy: 0.4500 - val_loss: 0.7253\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5534 - loss: 0.7172 - val_accuracy: 0.5000 - val_loss: 0.7265\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5466 - loss: 0.7134 - val_accuracy: 0.5000 - val_loss: 0.7269\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3748 - loss: 0.7436 - val_accuracy: 0.5000 - val_loss: 0.7267\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5325 - loss: 0.7157 - val_accuracy: 0.4500 - val_loss: 0.7256\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5914 - loss: 0.7109 - val_accuracy: 0.5000 - val_loss: 0.7250\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6449 - loss: 0.7093 - val_accuracy: 0.5000 - val_loss: 0.7253\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6226 - loss: 0.7058 - val_accuracy: 0.5000 - val_loss: 0.7259\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5906 - loss: 0.7051 - val_accuracy: 0.5000 - val_loss: 0.7257\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5150 - loss: 0.7260 - val_accuracy: 0.5500 - val_loss: 0.7237\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6209 - loss: 0.6931 - val_accuracy: 0.4500 - val_loss: 0.7280\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5979 - loss: 0.7050 - val_accuracy: 0.4500 - val_loss: 0.7278\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6870 - loss: 0.7020 - val_accuracy: 0.4500 - val_loss: 0.7271\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6945 - loss: 0.6636 - val_accuracy: 0.5000 - val_loss: 0.7241\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5971 - loss: 0.7196 - val_accuracy: 0.5000 - val_loss: 0.7241\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 0.6884 - val_accuracy: 0.4500 - val_loss: 0.7235\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5941 - loss: 0.7110 - val_accuracy: 0.5000 - val_loss: 0.7211\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6165 - loss: 0.7159 - val_accuracy: 0.4500 - val_loss: 0.7230\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5611 - loss: 0.7070 - val_accuracy: 0.4500 - val_loss: 0.7220\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5617 - loss: 0.7062 - val_accuracy: 0.4500 - val_loss: 0.7206\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6035 - loss: 0.7037 - val_accuracy: 0.4500 - val_loss: 0.7200\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7167 - loss: 0.6807 - val_accuracy: 0.4500 - val_loss: 0.7203\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5603 - loss: 0.7281 - val_accuracy: 0.5500 - val_loss: 0.7174\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5552 - loss: 0.6980 - val_accuracy: 0.4500 - val_loss: 0.7210\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6776 - loss: 0.6769 - val_accuracy: 0.4500 - val_loss: 0.7227\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5825 - loss: 0.7091 - val_accuracy: 0.5000 - val_loss: 0.7195\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5537 - loss: 0.7155 - val_accuracy: 0.4500 - val_loss: 0.7201\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6134 - loss: 0.6981 - val_accuracy: 0.4500 - val_loss: 0.7201\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5216 - loss: 0.7113 - val_accuracy: 0.4500 - val_loss: 0.7228\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6482 - loss: 0.6974 - val_accuracy: 0.4500 - val_loss: 0.7242\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6150 - loss: 0.7038 - val_accuracy: 0.4500 - val_loss: 0.7233\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6202 - loss: 0.7046 - val_accuracy: 0.4500 - val_loss: 0.7238\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7146 - loss: 0.6645 - val_accuracy: 0.4500 - val_loss: 0.7214\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5387 - loss: 0.7056 - val_accuracy: 0.4500 - val_loss: 0.7201\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6658 - loss: 0.6950 - val_accuracy: 0.5000 - val_loss: 0.7184\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7121 - loss: 0.6863 - val_accuracy: 0.4500 - val_loss: 0.7188\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6392 - loss: 0.6804 - val_accuracy: 0.5000 - val_loss: 0.7173\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6708 - loss: 0.6835 - val_accuracy: 0.5500 - val_loss: 0.7129\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5629 - loss: 0.7050 - val_accuracy: 0.5500 - val_loss: 0.7137\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6504 - loss: 0.6781 - val_accuracy: 0.4500 - val_loss: 0.7173\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5905 - loss: 0.7040 - val_accuracy: 0.5000 - val_loss: 0.7146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ae525fa70>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(8,)))\n",
    "model.add(Dense(32,activation='relu',kernel_regularizer=l2(0.01)))#l2 with weight decay of 0.01(penalizes large weights)\n",
    "\n",
    "model.add(Dropout(0.5))#half of the outputs will be dropped out\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=100,batch_size=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.395\n"
     ]
    }
   ],
   "source": [
    "#exercises for chapter 6\n",
    "\n",
    "#implement a perceptron\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y=make_classification(n_samples=1000,n_features=20,n_informative=15,n_redundant=5,random_state=7)#to make a binary classification dataset\n",
    " \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "\n",
    "#defining a perceptron model in a class\n",
    "class perceptron:\n",
    "    def _unit_step_func_(self,x):\n",
    "        return np.where(x>=0,1,-1)\n",
    "    def __init__(self,learning_rate=0.01,n_iters=1000):\n",
    "        self.lr=learning_rate\n",
    "        self.n_iters=n_iters\n",
    "        self.activation=self._unit_step_func_\n",
    "        \n",
    "        self.weight=None\n",
    "        self.bias=None\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        n_samples,n_features=X.shape\n",
    "        self.weight=np.zeros(n_features)\n",
    "        self.bias=0\n",
    "        y_=np.where(y<=0,-1,1)#put 1 where greater than 0 and -1 where less than zero\n",
    "        for i in range (self.n_iters):\n",
    "            for xi,xj in enumerate(X):# xi is the index and xj is the value stored\n",
    "                linearop=np.dot(xj,self.weight)+self.bias\n",
    "                y_pred=self.activation(linearop)\n",
    "                \n",
    "                update=self.lr*(y_[xi]-y_pred)\n",
    "                self.weight+=update*xj\n",
    "                self.bias+=update\n",
    "    \n",
    "    def predict(self,X):\n",
    "        linearop=np.dot(X,self.weight)+self.bias\n",
    "        y_pred=self.activation(linearop)\n",
    "        return y_pred\n",
    "\n",
    "p=perceptron(learning_rate=0.01,n_iters=100)\n",
    "p.fit(X_train,y_train)\n",
    "pred=p.predict(X_test)\n",
    "acc=accuracy_score(y_test,pred)\n",
    "print(acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10, -8.5, -7.3, -6.34, -5.572, -4.9576, -4.46608, -4.072864, -3.7582912, -3.50663296, -3.305306368, -3.1442450944, -3.01539607552, -2.912316860416, -2.8298534883328, -2.7638827906662398, -2.711106232532992, -2.6688849860263937, -2.635107988821115, -2.608086391056892, -2.5864691128455135, -2.569175290276411, -2.5553402322211287, -2.544272185776903, -2.5354177486215224, -2.528334198897218, -2.5226673591177744, -2.5181338872942196, -2.5145071098353755, -2.5116056878683004, -2.50928455029464, -2.5074276402357123, -2.5059421121885697, -2.5047536897508555, -2.5038029518006844, -2.5030423614405475, -2.502433889152438, -2.5019471113219502, -2.5015576890575604, -2.501246151246048, -2.5009969209968386, -2.500797536797471, -2.500638029437977, -2.5005104235503817, -2.5004083388403053, -2.5003266710722443, -2.5002613368577955, -2.5002090694862362, -2.500167255588989, -2.500133804471191, -2.5001070435769526]\n"
     ]
    }
   ],
   "source": [
    "#implementing gradient descent\n",
    "import matplotlib as plt\n",
    "def df(x):\n",
    "    return 2*x+5\n",
    "def gradient_descent(x1,learning_rate,n_iters):\n",
    "    x=x1\n",
    "    history=[x]\n",
    "    for i in range(n_iters):\n",
    "        grad=df(x)\n",
    "        x-=learning_rate*grad#minimizes the function ie finds global minima \n",
    "        history.append(x)\n",
    "    return history\n",
    "history=gradient_descent(x1=-10,learning_rate=0.1,n_iters=50)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5103 - loss: 2.6727  \n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6664 - loss: 1.7699  \n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7132 - loss: 1.4914\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7764 - loss: 1.2843  \n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7821 - loss: 1.1920  \n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8473 - loss: 1.0437  \n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8502 - loss: 0.9361  \n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8727 - loss: 0.9028\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.8363 - loss: 0.8793\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8775 - loss: 0.7673\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8921 - loss: 0.7146  \n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8853 - loss: 0.6811\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.8795 - loss: 0.6610\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8864 - loss: 0.6306  \n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9044 - loss: 0.5809\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 0.5731\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9062 - loss: 0.5365\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9111 - loss: 0.5361\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.5314  \n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9078 - loss: 0.4992\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.4781\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.4740  \n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.4742\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8965 - loss: 0.4577  \n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.4756\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.4762  \n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.4587  \n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.4501  \n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.4446  \n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.4620  \n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.4678\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.4494  \n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.4682  \n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.4644  \n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.4582  \n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9246 - loss: 0.4406  \n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.4444  \n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.4590  \n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9099 - loss: 0.4413\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9005 - loss: 0.4591\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.4291  \n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9117 - loss: 0.4561\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.4513  \n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.4269  \n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.4405\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.9082 - loss: 0.4286\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9192 - loss: 0.4434\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9076 - loss: 0.4318\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.4459  \n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.9337 - loss: 0.4209\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.4257\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.4544\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.4313\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.4368  \n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.4487  \n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.4293\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.4467  \n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9198 - loss: 0.4382  \n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.4650  \n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8895 - loss: 0.4466  \n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.4327  \n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8995 - loss: 0.4502  \n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.4458  \n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9101 - loss: 0.4517  \n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.4441  \n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.4257  \n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.4174  \n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.4279  \n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.4407  \n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9212 - loss: 0.4554  \n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.4084\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9292 - loss: 0.4054\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.4450\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.4514  \n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9185 - loss: 0.4132\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.4252  \n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.4116\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.4495  \n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8966 - loss: 0.4606\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9244 - loss: 0.4345  \n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9198 - loss: 0.4210  \n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.4488  \n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.4212  \n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.4190  \n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9016 - loss: 0.4338  \n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.4234  \n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.4467  \n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.4213  \n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.4360  \n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.4334  \n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.4416  \n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.4110  \n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9218 - loss: 0.4185  \n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.4460  \n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.4263  \n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.4230  \n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.4165  \n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9386 - loss: 0.4091\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.9315 - loss: 0.4547\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.4451  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21072f85d90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input,Dropout #for L1 and L2 dropout\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(20,)))\n",
    "model.add(Dense(32,activation='relu',kernel_regularizer=l1(0.01)))#adds a penalty so that model does not learn the dataset instead of the patterns\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_regularizer=l2(0.01)))#same goes for here\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.4386 - val_accuracy: 0.9438 - val_loss: 0.3852\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.4180 - val_accuracy: 0.9312 - val_loss: 0.3836\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.4236 - val_accuracy: 0.9312 - val_loss: 0.3839\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.4257 - val_accuracy: 0.9187 - val_loss: 0.3930\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.4238 - val_accuracy: 0.9250 - val_loss: 0.3918\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06270708],\n",
       "       [0.06665029],\n",
       "       [0.8119693 ],\n",
       "       [0.350564  ],\n",
       "       [0.87625426],\n",
       "       [0.97602224],\n",
       "       [0.2780019 ],\n",
       "       [0.8520075 ],\n",
       "       [0.09920334],\n",
       "       [0.10088603],\n",
       "       [0.8541679 ],\n",
       "       [0.7451796 ],\n",
       "       [0.7174516 ],\n",
       "       [0.9982595 ],\n",
       "       [0.97187775],\n",
       "       [0.53216034],\n",
       "       [0.981949  ],\n",
       "       [0.07736728],\n",
       "       [0.32294878],\n",
       "       [0.45723122],\n",
       "       [0.938365  ],\n",
       "       [0.7996003 ],\n",
       "       [0.23724648],\n",
       "       [0.933572  ],\n",
       "       [0.9869471 ],\n",
       "       [0.7892343 ],\n",
       "       [0.0383876 ],\n",
       "       [0.2694029 ],\n",
       "       [0.9713646 ],\n",
       "       [0.10576987],\n",
       "       [0.1293114 ],\n",
       "       [0.34554595],\n",
       "       [0.8173169 ],\n",
       "       [0.02918066],\n",
       "       [0.01741909],\n",
       "       [0.57841706],\n",
       "       [0.61399746],\n",
       "       [0.5451454 ],\n",
       "       [0.36312756],\n",
       "       [0.8513146 ],\n",
       "       [0.9367498 ],\n",
       "       [0.02793258],\n",
       "       [0.0279134 ],\n",
       "       [0.04284625],\n",
       "       [0.04909546],\n",
       "       [0.6400554 ],\n",
       "       [0.8866152 ],\n",
       "       [0.03944764],\n",
       "       [0.73481256],\n",
       "       [0.7419715 ],\n",
       "       [0.32842585],\n",
       "       [0.94963765],\n",
       "       [0.9816983 ],\n",
       "       [0.6970348 ],\n",
       "       [0.99377257],\n",
       "       [0.24287681],\n",
       "       [0.11756523],\n",
       "       [0.97520643],\n",
       "       [0.0504518 ],\n",
       "       [0.9092444 ],\n",
       "       [0.8830058 ],\n",
       "       [0.06916852],\n",
       "       [0.73423177],\n",
       "       [0.00679188],\n",
       "       [0.7807882 ],\n",
       "       [0.7222948 ],\n",
       "       [0.8152543 ],\n",
       "       [0.7795459 ],\n",
       "       [0.00513727],\n",
       "       [0.00529102],\n",
       "       [0.92946553],\n",
       "       [0.61787426],\n",
       "       [0.947685  ],\n",
       "       [0.38732478],\n",
       "       [0.06076716],\n",
       "       [0.05353418],\n",
       "       [0.09102866],\n",
       "       [0.855992  ],\n",
       "       [0.13571009],\n",
       "       [0.96571815],\n",
       "       [0.07310168],\n",
       "       [0.61060846],\n",
       "       [0.9113994 ],\n",
       "       [0.5934299 ],\n",
       "       [0.40503207],\n",
       "       [0.6330348 ],\n",
       "       [0.11450738],\n",
       "       [0.2670834 ],\n",
       "       [0.13761415],\n",
       "       [0.12167131],\n",
       "       [0.9588554 ],\n",
       "       [0.79284346],\n",
       "       [0.7576535 ],\n",
       "       [0.01562285],\n",
       "       [0.02751871],\n",
       "       [0.99064016],\n",
       "       [0.01228568],\n",
       "       [0.94487107],\n",
       "       [0.01952457],\n",
       "       [0.7778906 ],\n",
       "       [0.79026616],\n",
       "       [0.04412662],\n",
       "       [0.07137571],\n",
       "       [0.24409059],\n",
       "       [0.06851793],\n",
       "       [0.9040353 ],\n",
       "       [0.95855767],\n",
       "       [0.26689583],\n",
       "       [0.7988639 ],\n",
       "       [0.02280056],\n",
       "       [0.08274129],\n",
       "       [0.86812335],\n",
       "       [0.55235636],\n",
       "       [0.08809481],\n",
       "       [0.79117817],\n",
       "       [0.71830773],\n",
       "       [0.8486037 ],\n",
       "       [0.9924546 ],\n",
       "       [0.99764985],\n",
       "       [0.45504633],\n",
       "       [0.67020917],\n",
       "       [0.04719614],\n",
       "       [0.09027937],\n",
       "       [0.44345936],\n",
       "       [0.92973584],\n",
       "       [0.14457966],\n",
       "       [0.02456498],\n",
       "       [0.9638256 ],\n",
       "       [0.95296025],\n",
       "       [0.06162053],\n",
       "       [0.13729563],\n",
       "       [0.87219644],\n",
       "       [0.03922156],\n",
       "       [0.7873215 ],\n",
       "       [0.3206603 ],\n",
       "       [0.8389085 ],\n",
       "       [0.01878668],\n",
       "       [0.94794506],\n",
       "       [0.01886902],\n",
       "       [0.9527671 ],\n",
       "       [0.96620804],\n",
       "       [0.10418259],\n",
       "       [0.9885954 ],\n",
       "       [0.9224949 ],\n",
       "       [0.9023349 ],\n",
       "       [0.9929273 ],\n",
       "       [0.69872344],\n",
       "       [0.00671939],\n",
       "       [0.9682532 ],\n",
       "       [0.90814555],\n",
       "       [0.9672223 ],\n",
       "       [0.1117074 ],\n",
       "       [0.15171388],\n",
       "       [0.7253864 ],\n",
       "       [0.4620925 ],\n",
       "       [0.9974178 ],\n",
       "       [0.95738244],\n",
       "       [0.04142264],\n",
       "       [0.21183737],\n",
       "       [0.9032735 ],\n",
       "       [0.9765883 ],\n",
       "       [0.06558767],\n",
       "       [0.91103375],\n",
       "       [0.3399761 ],\n",
       "       [0.8824271 ],\n",
       "       [0.07307471],\n",
       "       [0.51279604],\n",
       "       [0.25445366],\n",
       "       [0.22536938],\n",
       "       [0.93411016],\n",
       "       [0.986216  ],\n",
       "       [0.4859714 ],\n",
       "       [0.10995152],\n",
       "       [0.03686957],\n",
       "       [0.9800297 ],\n",
       "       [0.08571775],\n",
       "       [0.8918089 ],\n",
       "       [0.19163686],\n",
       "       [0.20956856],\n",
       "       [0.5770674 ],\n",
       "       [0.04860226],\n",
       "       [0.46073815],\n",
       "       [0.9597465 ],\n",
       "       [0.9718295 ],\n",
       "       [0.5122806 ],\n",
       "       [0.37926373],\n",
       "       [0.9838648 ],\n",
       "       [0.18882306],\n",
       "       [0.02642852],\n",
       "       [0.04252011],\n",
       "       [0.01517803],\n",
       "       [0.01832825],\n",
       "       [0.01376544],\n",
       "       [0.98407286],\n",
       "       [0.23851268],\n",
       "       [0.09947779],\n",
       "       [0.02548746],\n",
       "       [0.9497038 ],\n",
       "       [0.16118109],\n",
       "       [0.40905267]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping and dropout\n",
    "#train test split already exists\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model1=Sequential()\n",
    "model1.add(Input(shape=(20,)))#since 20 attributes\n",
    "model1.add(Dense(32,activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "es=EarlyStopping(patience=3)#this means if for 3 epochs the accuracy does not increase as compared to validation accuracy the model training will be stopped\n",
    "\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=10,validation_split=0.2,callbacks=[es])\n",
    "\n",
    "model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[-1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a=tf.constant([2])\n",
    "b=tf.constant([3])\n",
    "c=tf.add(a,b)\n",
    "d=tf.subtract(a,b)\n",
    "print(c.numpy())#makes the c to a numpy array instead of a tensor \n",
    "print(d.numpy())\n",
    "\n",
    "#sessions have been removed\n",
    "#with tf.Session() as session:\n",
    "#   result=session.run(c)\n",
    "#    print(result)\n",
    "#    result=session.run(d)\n",
    "#    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "#graph creation \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()  # Disables eager execution in tensorflow 2\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():  # Define a computation graph\n",
    "    x = tf.constant(8, name='xconst')\n",
    "    y = tf.constant(5, name='yconst')\n",
    "    sum_result = tf.add(x, y, name='xysum')\n",
    "\n",
    "# Create a session explicitly (without using `with`) \n",
    "sess = tf.Session(graph=graph)\n",
    "result = sess.run(sum_result)\n",
    "print(result)  # Output: 13\n",
    "sess.close()  # Always close the session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#building a neural network using tensorflow\n",
    "import tensorflow as tf\n",
    "ninputs=10\n",
    "nout=2\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(ninputs,),name='input'),\n",
    "    tf.keras.layers.Dense(ninputs,activation='relu',name='hidden'),\n",
    "    tf.keras.layers.Dense(nout,name='output')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])#loss function used is generally used for multiclass labels\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5429 - loss: 0.0890 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09246403723955154, 0.550000011920929]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the neural network built\n",
    "import numpy as np\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),loss='mse',metrics=['accuracy']) #using gradient descent\n",
    "\n",
    "#create dummy data\n",
    "X_train = np.random.rand(100, ninputs).astype(np.float32)  # 100 samples, 10 features\n",
    "y_train = np.random.rand(100, nout).astype(np.float32)  # 100 samples, 2 features\n",
    "\n",
    "model.fit(X_train,y_train,epochs=100,verbose=0,batch_size=32)#verbose=0 hides the epochs and it runs into a computation graph itself so no need to run sessions\n",
    "\n",
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.5180 - loss: 1.3716 - val_accuracy: 0.4500 - val_loss: 1.4275\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4922 - loss: 1.3351 - val_accuracy: 0.4500 - val_loss: 1.3896\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4516 - loss: 1.3145 - val_accuracy: 0.4500 - val_loss: 1.3548\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4477 - loss: 1.2826 - val_accuracy: 0.5500 - val_loss: 1.3236\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4906 - loss: 1.2402 - val_accuracy: 0.5500 - val_loss: 1.2954\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4492 - loss: 1.2236 - val_accuracy: 0.5500 - val_loss: 1.2697\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4570 - loss: 1.1988 - val_accuracy: 0.4500 - val_loss: 1.2463\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4672 - loss: 1.1907 - val_accuracy: 0.4500 - val_loss: 1.2242\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4789 - loss: 1.1683 - val_accuracy: 0.4500 - val_loss: 1.2036\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4711 - loss: 1.1585 - val_accuracy: 0.4500 - val_loss: 1.1841\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4461 - loss: 1.1315 - val_accuracy: 0.4500 - val_loss: 1.1657\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4953 - loss: 1.1064 - val_accuracy: 0.4500 - val_loss: 1.1480\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4836 - loss: 1.0988 - val_accuracy: 0.4500 - val_loss: 1.1307\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5211 - loss: 1.0778 - val_accuracy: 0.4500 - val_loss: 1.1140\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4820 - loss: 1.0672 - val_accuracy: 0.4500 - val_loss: 1.0980\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5391 - loss: 1.0495 - val_accuracy: 0.4500 - val_loss: 1.0823\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5078 - loss: 1.0379 - val_accuracy: 0.4500 - val_loss: 1.0671\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4922 - loss: 1.0262 - val_accuracy: 0.5000 - val_loss: 1.0522\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5234 - loss: 1.0050 - val_accuracy: 0.5000 - val_loss: 1.0377\n",
      "Epoch 20/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5414 - loss: 0.9890 - val_accuracy: 0.5000 - val_loss: 1.0235\n",
      "Epoch 21/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5023 - loss: 0.9797 - val_accuracy: 0.5000 - val_loss: 1.0095\n",
      "Epoch 22/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5141 - loss: 0.9613 - val_accuracy: 0.5000 - val_loss: 0.9958\n",
      "Epoch 23/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5344 - loss: 0.9462 - val_accuracy: 0.5000 - val_loss: 0.9823\n",
      "Epoch 24/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5250 - loss: 0.9340 - val_accuracy: 0.5000 - val_loss: 0.9689\n",
      "Epoch 25/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5680 - loss: 0.9205 - val_accuracy: 0.5000 - val_loss: 0.9558\n",
      "Epoch 26/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5914 - loss: 0.9105 - val_accuracy: 0.5000 - val_loss: 0.9430\n",
      "Epoch 27/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5484 - loss: 0.8983 - val_accuracy: 0.5000 - val_loss: 0.9302\n",
      "Epoch 28/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5562 - loss: 0.8865 - val_accuracy: 0.5000 - val_loss: 0.9177\n",
      "Epoch 29/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5562 - loss: 0.8773 - val_accuracy: 0.5000 - val_loss: 0.9055\n",
      "Epoch 30/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5680 - loss: 0.8679 - val_accuracy: 0.5000 - val_loss: 0.8935\n",
      "Epoch 31/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5484 - loss: 0.8507 - val_accuracy: 0.5000 - val_loss: 0.8817\n",
      "Epoch 32/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5523 - loss: 0.8405 - val_accuracy: 0.5000 - val_loss: 0.8702\n",
      "Epoch 33/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5172 - loss: 0.8261 - val_accuracy: 0.5000 - val_loss: 0.8588\n",
      "Epoch 34/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5562 - loss: 0.8184 - val_accuracy: 0.5500 - val_loss: 0.8475\n",
      "Epoch 35/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5328 - loss: 0.8042 - val_accuracy: 0.5500 - val_loss: 0.8362\n",
      "Epoch 36/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5367 - loss: 0.7906 - val_accuracy: 0.5500 - val_loss: 0.8253\n",
      "Epoch 37/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5703 - loss: 0.7802 - val_accuracy: 0.5500 - val_loss: 0.8143\n",
      "Epoch 38/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5898 - loss: 0.7696 - val_accuracy: 0.5500 - val_loss: 0.8036\n",
      "Epoch 39/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5586 - loss: 0.7634 - val_accuracy: 0.5500 - val_loss: 0.7932\n",
      "Epoch 40/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5781 - loss: 0.7501 - val_accuracy: 0.5500 - val_loss: 0.7828\n",
      "Epoch 41/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5641 - loss: 0.7419 - val_accuracy: 0.5500 - val_loss: 0.7726\n",
      "Epoch 42/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5211 - loss: 0.7298 - val_accuracy: 0.5500 - val_loss: 0.7624\n",
      "Epoch 43/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5719 - loss: 0.7191 - val_accuracy: 0.5500 - val_loss: 0.7524\n",
      "Epoch 44/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5016 - loss: 0.7117 - val_accuracy: 0.5500 - val_loss: 0.7424\n",
      "Epoch 45/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5445 - loss: 0.6976 - val_accuracy: 0.5500 - val_loss: 0.7327\n",
      "Epoch 46/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5094 - loss: 0.6884 - val_accuracy: 0.5500 - val_loss: 0.7230\n",
      "Epoch 47/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5805 - loss: 0.6806 - val_accuracy: 0.5500 - val_loss: 0.7135\n",
      "Epoch 48/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5625 - loss: 0.6721 - val_accuracy: 0.5500 - val_loss: 0.7042\n",
      "Epoch 49/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5508 - loss: 0.6626 - val_accuracy: 0.5500 - val_loss: 0.6951\n",
      "Epoch 50/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5523 - loss: 0.6559 - val_accuracy: 0.5500 - val_loss: 0.6861\n",
      "Epoch 51/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5430 - loss: 0.6459 - val_accuracy: 0.5500 - val_loss: 0.6771\n",
      "Epoch 52/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5820 - loss: 0.6363 - val_accuracy: 0.5000 - val_loss: 0.6683\n",
      "Epoch 53/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5938 - loss: 0.6285 - val_accuracy: 0.5000 - val_loss: 0.6597\n",
      "Epoch 54/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5883 - loss: 0.6180 - val_accuracy: 0.5000 - val_loss: 0.6512\n",
      "Epoch 55/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5844 - loss: 0.6133 - val_accuracy: 0.5000 - val_loss: 0.6428\n",
      "Epoch 56/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5742 - loss: 0.6058 - val_accuracy: 0.5000 - val_loss: 0.6347\n",
      "Epoch 57/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5273 - loss: 0.5957 - val_accuracy: 0.5000 - val_loss: 0.6267\n",
      "Epoch 58/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5430 - loss: 0.5846 - val_accuracy: 0.5000 - val_loss: 0.6188\n",
      "Epoch 59/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5375 - loss: 0.5790 - val_accuracy: 0.5000 - val_loss: 0.6110\n",
      "Epoch 60/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5414 - loss: 0.5726 - val_accuracy: 0.5000 - val_loss: 0.6032\n",
      "Epoch 61/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6219 - loss: 0.5635 - val_accuracy: 0.5000 - val_loss: 0.5956\n",
      "Epoch 62/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5906 - loss: 0.5550 - val_accuracy: 0.5000 - val_loss: 0.5881\n",
      "Epoch 63/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6062 - loss: 0.5518 - val_accuracy: 0.5000 - val_loss: 0.5808\n",
      "Epoch 64/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6062 - loss: 0.5373 - val_accuracy: 0.5000 - val_loss: 0.5736\n",
      "Epoch 65/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5828 - loss: 0.5400 - val_accuracy: 0.5000 - val_loss: 0.5665\n",
      "Epoch 66/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5648 - loss: 0.5255 - val_accuracy: 0.5000 - val_loss: 0.5596\n",
      "Epoch 67/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6023 - loss: 0.5179 - val_accuracy: 0.5000 - val_loss: 0.5527\n",
      "Epoch 68/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6023 - loss: 0.5166 - val_accuracy: 0.5000 - val_loss: 0.5459\n",
      "Epoch 69/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6023 - loss: 0.5060 - val_accuracy: 0.5000 - val_loss: 0.5391\n",
      "Epoch 70/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5906 - loss: 0.5002 - val_accuracy: 0.5000 - val_loss: 0.5325\n",
      "Epoch 71/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5906 - loss: 0.4881 - val_accuracy: 0.5000 - val_loss: 0.5260\n",
      "Epoch 72/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5891 - loss: 0.4872 - val_accuracy: 0.5000 - val_loss: 0.5197\n",
      "Epoch 73/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6359 - loss: 0.4839 - val_accuracy: 0.5000 - val_loss: 0.5132\n",
      "Epoch 74/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6008 - loss: 0.4742 - val_accuracy: 0.5000 - val_loss: 0.5068\n",
      "Epoch 75/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6008 - loss: 0.4679 - val_accuracy: 0.5000 - val_loss: 0.5004\n",
      "Epoch 76/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6164 - loss: 0.4608 - val_accuracy: 0.5000 - val_loss: 0.4943\n",
      "Epoch 77/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6047 - loss: 0.4580 - val_accuracy: 0.5000 - val_loss: 0.4882\n",
      "Epoch 78/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5242 - loss: 0.4532 - val_accuracy: 0.5000 - val_loss: 0.4822\n",
      "Epoch 79/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5789 - loss: 0.4443 - val_accuracy: 0.5000 - val_loss: 0.4762\n",
      "Epoch 80/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6062 - loss: 0.4388 - val_accuracy: 0.5000 - val_loss: 0.4703\n",
      "Epoch 81/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5203 - loss: 0.4335 - val_accuracy: 0.5000 - val_loss: 0.4647\n",
      "Epoch 82/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5789 - loss: 0.4277 - val_accuracy: 0.5000 - val_loss: 0.4591\n",
      "Epoch 83/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5750 - loss: 0.4243 - val_accuracy: 0.5000 - val_loss: 0.4536\n",
      "Epoch 84/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6477 - loss: 0.4175 - val_accuracy: 0.5000 - val_loss: 0.4482\n",
      "Epoch 85/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6125 - loss: 0.4127 - val_accuracy: 0.5000 - val_loss: 0.4429\n",
      "Epoch 86/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6266 - loss: 0.4043 - val_accuracy: 0.5000 - val_loss: 0.4378\n",
      "Epoch 87/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6031 - loss: 0.4028 - val_accuracy: 0.5000 - val_loss: 0.4327\n",
      "Epoch 88/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6227 - loss: 0.3960 - val_accuracy: 0.5000 - val_loss: 0.4276\n",
      "Epoch 89/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6109 - loss: 0.3926 - val_accuracy: 0.5000 - val_loss: 0.4227\n",
      "Epoch 90/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6461 - loss: 0.3896 - val_accuracy: 0.5000 - val_loss: 0.4179\n",
      "Epoch 91/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5836 - loss: 0.3823 - val_accuracy: 0.5000 - val_loss: 0.4131\n",
      "Epoch 92/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6305 - loss: 0.3832 - val_accuracy: 0.5000 - val_loss: 0.4084\n",
      "Epoch 93/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6422 - loss: 0.3715 - val_accuracy: 0.5000 - val_loss: 0.4038\n",
      "Epoch 94/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6070 - loss: 0.3676 - val_accuracy: 0.5000 - val_loss: 0.3993\n",
      "Epoch 95/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6148 - loss: 0.3678 - val_accuracy: 0.5000 - val_loss: 0.3947\n",
      "Epoch 96/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6500 - loss: 0.3603 - val_accuracy: 0.5000 - val_loss: 0.3903\n",
      "Epoch 97/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6187 - loss: 0.3616 - val_accuracy: 0.4500 - val_loss: 0.3859\n",
      "Epoch 98/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6031 - loss: 0.3499 - val_accuracy: 0.4500 - val_loss: 0.3815\n",
      "Epoch 99/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6070 - loss: 0.3456 - val_accuracy: 0.4500 - val_loss: 0.3772\n",
      "Epoch 100/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6539 - loss: 0.3457 - val_accuracy: 0.4500 - val_loss: 0.3729\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">398</span> (1.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m398\u001b[0m (1.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266</span> (1.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m266\u001b[0m (1.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#early stopping and regularization combined in tensorflow (earlystopping is done manually in the book but i will use the library) \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "reg=l2(0.1)#0.1 is the penalty term\n",
    "lossfn=MeanSquaredError()\n",
    "opt=Adam()\n",
    "es=EarlyStopping(patience=3,monitor='val_loss',restore_best_weights=True)#early stopping function\n",
    "model=Sequential([\n",
    "    tf.keras.Input(shape=(ninputs,),name='input'),\n",
    "    tf.keras.layers.Dense(ninputs,activation='relu',name='hidden',kernel_regularizer=reg),#here i added the regularizer\n",
    "    tf.keras.layers.Dense(nout,name='output',kernel_regularizer=reg)\n",
    "])\n",
    "model.compile(loss=lossfn,optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100,validation_split=0.2,callbacks=[es],verbose=1)#this is where i added the earlystopping during fit\n",
    "#early stoppin stops training at a higher epoch value only\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"savedmodels/my_model.keras\") #saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">398</span> (1.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m398\u001b[0m (1.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266</span> (1.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m266\u001b[0m (1.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the model\n",
    "from tensorflow.keras import models\n",
    "loaded_model=models.load_model(\"./savedmodels/my_model.keras\")\n",
    "loaded_model.summary()#same as the above model after training\n",
    "#after the model is loaded the model can be trained or used using the variable name it was stored into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for deployment its highly recommended that we use the SavedModel format to save the model(automatically does that when model.save is used)\n",
    "#it can save in a hdf5 format (.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#practical exercises\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.layers import Input,Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "lossfunc=MeanSquaredError()\n",
    "X,y=make_regression(n_samples=1000,n_features=10,noise=0.1,random_state=42)#to get random dataset for regression\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)#split into train test split\n",
    "mymodel=Sequential([\n",
    "    Input(shape=(10,)),#only defines the input layers shape nothing else\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "mymodel.compile(loss=lossfunc,optimizer='adam',metrics=['accuracy'])\n",
    "mymodel.fit(X_train,y_train,validation_split=0.2,epochs=100,verbose=0)\n",
    "mymodel.save('savedmodels/exercisemodel.keras')\n",
    "loaded=load_model('savedmodels/exercisemodel.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,157</span> (4.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,157\u001b[0m (4.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">772</span> (3.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m772\u001b[0m (3.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,157</span> (4.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,157\u001b[0m (4.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m385\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">772</span> (3.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m772\u001b[0m (3.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mymodel.summary()\n",
    "loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
